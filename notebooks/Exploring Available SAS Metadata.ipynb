{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a755df56",
   "metadata": {},
   "source": [
    "# Exploring SAS file metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a64c27",
   "metadata": {},
   "source": [
    "Anyone working with the OAI structured data has a choice, import the data from ASCII or SAS. This project chooses to rely on the SAS data. There are over 9,000 different variables recorded by OAI.  Writing heuristics to guess the optimal data types for all 9,000 is likely to be more flawed than leveraging what we can from SAS metadata. This notebook explores what SAS metadata can be pulled out by pyreadstat (there may be metadata it ignores; I haven't verified it's code). It is mostly here as a record of discovery and not typically needed for anyone looking to jump into the data.\n",
    "\n",
    "The data seems to be stored in two ways:\n",
    "* A collection of sas7bdat and sas7bcat files.\n",
    "* In the SAS propietary CPORT format (labeled .xpt instead of .cpt)\n",
    "\n",
    "Thanks to the OAI employee who chose to support a closed source, proprietary format. While SAS was common enough in 2012, chosing proprietary formats for govt. owned data was already bad form by then. Further, the files are listed as .XPT files just to keep users confused (you can find users trying to solve this mystery for this exact dataset in internet forums).  Not having a SAS instance, we have to ignore the the CPORT files and hope no information is lost in doing so. It isn't also clear why the data is saved in a compressed format (save space) but also bundled with a non-compressed form (benefits of compression lost). Maybe historical reasons.\n",
    "\n",
    "Subtle details may change between OAI release versions. Thus, once facts are established, they are encoded as assertions that can be verified when a new version of the data is released."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ea12f",
   "metadata": {},
   "source": [
    "## Setup / Imports / Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7cf801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyreadstat\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "data_dir = '../data/structured_data/'\n",
    "pdfs_dir = '../data/pdfs/General/Formats_SAS/'\n",
    "\n",
    "# Metadata values pulled out by pyreadstat\n",
    "meta_vars = [ 'column_labels',\n",
    " 'column_names',\n",
    " 'column_names_to_labels',\n",
    " 'file_encoding',\n",
    " 'file_format',\n",
    " 'file_label',\n",
    " 'missing_ranges',\n",
    " 'missing_user_values',\n",
    " 'notes',\n",
    " 'number_columns',\n",
    " 'number_rows',\n",
    " 'original_variable_types',\n",
    " 'readstat_variable_types',\n",
    " 'table_name',\n",
    " 'value_labels',\n",
    " 'variable_alignment',\n",
    " 'variable_display_width',\n",
    " 'variable_measure',\n",
    " 'variable_storage_width',\n",
    " 'variable_to_label',\n",
    " 'variable_value_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd56fc",
   "metadata": {},
   "source": [
    "## Read in all metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e296209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All SAS files\n",
    "all_files = os.listdir(data_dir)\n",
    "all_files = [x for x in all_files if '.sas7bdat' in x]\n",
    "all_files.remove('sageancillarystudy_formats.sas7bdat') ## At a binary level this seems like another CPORT file. WTF?\n",
    "all_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_meta = {}\n",
    "for filename in all_files:\n",
    "    meta_dict['Filename'].append(filename)\n",
    "    _, meta = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename,\n",
    "                                                         catalog_file=data_dir + 'formats.sas7bcat',\n",
    "                                                         num_processes=6, metadataonly=True)\n",
    "    files_meta[filename] = meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27350d9",
   "metadata": {},
   "source": [
    "### See what metadata variable values are common across all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what metadata is collected across all files\n",
    "# if a single value, list it.\n",
    "# if a collection store the size\n",
    "\n",
    "# create storage dict\n",
    "meta_dict = {v: [] for v in meta_vars}\n",
    "meta_dict['Filename'] = []\n",
    "\n",
    "for file, meta in files_meta.items():\n",
    "    meta_dict['Filename'].append(filename)\n",
    "\n",
    "    for mv in meta_vars:\n",
    "        var = getattr(meta, mv)\n",
    "        if var:\n",
    "            if isinstance(var, int):\n",
    "                meta_dict[mv].append(var)\n",
    "            elif isinstance(var, str):\n",
    "                meta_dict[mv].append(var)\n",
    "            else:\n",
    "                meta_dict[mv].append(len(var))\n",
    "        else:\n",
    "             meta_dict[mv].append(None)\n",
    "\n",
    "df = pd.DataFrame(meta_dict).set_index('Filename')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks on columns that should all have the same number of values and same keys in their dicts\n",
    "# - failure means the data (or pyreaadstat) has changed since this was written\n",
    "for file, meta in files_meta.items():\n",
    "    assert meta.number_columns == len(meta.column_labels)\n",
    "    assert meta.number_columns == len(meta.column_names)\n",
    "    # Do column_names + column_labels = column_names_to_labels?\n",
    "    assert set(meta.column_labels) == set(meta.column_names_to_labels.values())\n",
    "    \n",
    "    # Do all variables match a column name?\n",
    "    names = set(meta.column_names)\n",
    "    assert len(names ^ set(meta.column_names_to_labels.keys())) == 0\n",
    "    assert len(names ^ set(meta.original_variable_types.keys())) == 0\n",
    "    assert len(names ^ set(meta.readstat_variable_types.keys())) == 0\n",
    "    assert len(names ^ set(meta.variable_alignment.keys())) == 0\n",
    "    assert len(names ^ set(meta.variable_display_width.keys())) == 0\n",
    "    assert len(names ^ set(meta.variable_storage_width.keys())) == 0\n",
    "    assert names >= set(meta.variable_to_label.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List metadata variables which are empty for all files\n",
    "\n",
    "print(str(list(df.columns[df.isna().all()].sort_values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a3836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# - failure means the data (or pyreaadstat) has changed since this was written\n",
    "empty_vars = ['missing_ranges', 'missing_user_values', 'notes', 'value_labels', 'variable_value_labels']\n",
    "for var in empty_vars:\n",
    "    assert df[var].isna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns have an occasional empty value?\n",
    "\n",
    "incomplete = set(df.columns[df.isna().any()]) - set(df.columns[df.isna().all()])\n",
    "for x in incomplete:\n",
    "    print(x + ': ' + str(df[x].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6618b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique valeues exist for the remaining metadata variables?\n",
    "for col in df.columns[~df.isna().any()]:\n",
    "    print(col + ': ' + str(len(df[col].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f6835",
   "metadata": {},
   "source": [
    "So `file_encoding`, `file_format` are the same across all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4533643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# - failure means the data (or pyreaadstat) has changed since this was written\n",
    "assert len(list(df['file_encoding'].unique())) == 1\n",
    "assert list(df['file_encoding'].unique())[0] == 'WINDOWS-1252'\n",
    "assert len(list(df['file_format'].unique())) == 1\n",
    "assert list(df['file_format'].unique())[0] == 'sas7bdat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9232e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the unique values occur for given variable dictionaries\n",
    "col_list = ['original_variable_types', 'readstat_variable_types', 'variable_alignment', 'variable_display_width', 'variable_measure', 'variable_storage_width', 'variable_to_label']\n",
    "\n",
    "col_sets = {c: set() for c in col_list}\n",
    "for file, meta in files_meta.items():\n",
    "    for col in col_list:\n",
    "        var = getattr(meta, col)\n",
    "        if var:\n",
    "            if isinstance(var, dict):\n",
    "                col_sets[col].update(var.values())\n",
    "            else:\n",
    "                col_sets[col].update(var)\n",
    "                \n",
    "for col, vals in col_sets.items():\n",
    "    print(col + '(' + str(len(vals)) + '): ' + str(list(vals)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sets['original_variable_types'] - col_sets['variable_to_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389a399",
   "metadata": {},
   "source": [
    "So it seems that only `original_variable_types`, `variable_storage_width`, `variable_to_label` have anything unique to say about a variable (aside from variable/column names and labels). As shown several cells above, `original_variable_types` has a dict value for every variable (even if that value is `NULL`). `variable_to_label` seems to have the same data, but leaves out variables that don't use a value list. 'Value labels' seem to be SAS's form of user defined formats ( https://libguides.library.kent.edu/SAS/UserDefinedFormats ), somewhat like categories in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# - failure means the data (or pyreaadstat) has changed since this was written\n",
    "assert col_sets['readstat_variable_types'] == {'double', 'string'}\n",
    "assert col_sets['variable_alignment'] == {'unknown'}\n",
    "assert col_sets['variable_display_width'] == {0}\n",
    "assert col_sets['variable_measure'] == {'unknown'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24b2ed",
   "metadata": {},
   "source": [
    "## Check for differences in format files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5747f01c",
   "metadata": {},
   "source": [
    "There seem to be two competing SAS catalog files*:\n",
    "* `../data/pdfs/General/Formats_SAS/formats.sas7bcat`\n",
    "* `../data/structured_data/formats.sas7bcat`\n",
    "\n",
    "At a binary level, they are different, let's look at them as far as pyreadstat can determine. \n",
    "\n",
    "*(Ignoring the `kMRI_SQ_WORMS_Link_Formats.sas7bcat` file for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, local_cat = pyreadstat.read_sas7bcat(data_dir + 'formats.sas7bcat')\n",
    "_, pdf_cat = pyreadstat.read_sas7bcat(pdfs_dir + 'formats.sas7bcat')\n",
    "\n",
    "for cat in [local_cat, pdf_cat]:\n",
    "    for v in meta_vars:\n",
    "        var = getattr(cat,v)\n",
    "        if var:\n",
    "            if isinstance(var, int):\n",
    "                print(v + ': ' + str(var))\n",
    "            else:\n",
    "                print(v + ' - ' + str(len(var)))\n",
    "        else:\n",
    "            print(v + ' - empty')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb11abf0",
   "metadata": {},
   "source": [
    "They seem the same. Both only contain 'value_labels', SAS's user defined categories. Confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the dicts of the local catalog vs the one in the pdfs dir\n",
    "# - each is a dict of value dicts\n",
    "# - this is more code than normally needed because pyreadstat is creating NaN keys\n",
    "\n",
    "# At the top level, both have the same keys\n",
    "assert set(local_cat.value_labels.keys()) == set(pdf_cat.value_labels.keys())\n",
    "\n",
    "for k1, v1 in local_cat.value_labels.items():\n",
    "    # Get both sub dictionaries\n",
    "    v1_list = [(k,v) for k,v in v1.items()]\n",
    "    pdf_v1_list = [(k,v) for k,v in pdf_cat.value_labels[k1].items()]\n",
    "        \n",
    "    for (k2, v2) in v1_list:\n",
    "        # Confirm match exists\n",
    "        key_match = False\n",
    "        for (pdf_k2, pdf_v2) in pdf_v1_list:\n",
    "            if pdf_k2 == k2 or (isinstance(k2, float) and math.isnan(k2) and math.isnan(pdf_k2)):\n",
    "                key_match = True\n",
    "                if pdf_v2 == v2:\n",
    "                    break\n",
    "                else:\n",
    "                    # Mis-match on sub-dict values\n",
    "                    print('Dict[' + str(k1) + '][' + str(k2) + ']: [local v: ' + v2 + ']\\t[pdf v: ' + pdf_v2 + ']')\n",
    "                    break\n",
    "        if not key_match:\n",
    "            print('Dict[' + str(k1) + '): [local k: ' + str(k2) + ' had no match in: ' +  str([k for (k,v) in pdf_v1_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the order see if any keys exist in the PDF versions that don't exist in the local catalog files\n",
    "\n",
    "for k1, v1 in pdf_cat.value_labels.items():\n",
    "    # Get both sub dictionaries\n",
    "    v1_list = [(k,v) for k,v in v1.items()]\n",
    "    local_v1_list = [(k,v) for k,v in local_cat.value_labels[k1].items()]\n",
    "        \n",
    "    for (k2, v2) in v1_list:\n",
    "        # Confirm match exists\n",
    "        key_match = False\n",
    "        for (local_k2, local_v2) in local_v1_list:\n",
    "            if local_k2 == k2 or (isinstance(k2, float) and math.isnan(k2) and math.isnan(local_k2)):\n",
    "                key_match = True\n",
    "                if local_v2 == v2:\n",
    "                    break\n",
    "        if not key_match:\n",
    "            print('Dict[' + str(k1) + '): [pdf k: ' + str(k2) + ' had no match in: ' +  str([k for (k,v) in local_v1_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a1b203",
   "metadata": {},
   "source": [
    "So two keys shipped with the data aren't in the catalog file shipped with the PDFs. Seven seem to have minor differences in their label text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are any of the conflicting value dicts present in this data set?\n",
    "conflicting_value_labels = {'$SYNACCP', 'WTCHG', 'CRTMRPH', 'MMMRPH'}\n",
    "col_sets['variable_to_label']\n",
    "\n",
    "print(conflicting_value_labels & col_sets['variable_to_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad086a2",
   "metadata": {},
   "source": [
    "### Undefined data formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a65df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are their any variable types that aren't user defined?\n",
    "undefined_set = col_sets['variable_to_label'] - set(local_cat.value_labels.keys())\n",
    "print(undefined_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61551227",
   "metadata": {},
   "source": [
    "* $ in SAS means character data\n",
    "* BEST is numeric data that lets the system chose the best display format\n",
    "* MMDDYY is obviously a date\n",
    "\n",
    "I haven't found documentation for the rest ( https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.5/leforinforref/p0z62k899n6a7wn1r5in6q5253v1.htm ). Formats whose definitions weren't exported?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562db93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which data sets contain these undefined formats\n",
    "undefined_set.remove('$')\n",
    "undefined_set.remove('BEST')\n",
    "undefined_set.remove('MMDDYY')\n",
    "\n",
    "\n",
    "for filename, meta in files_meta.items():\n",
    "    vls = set(meta.variable_to_label.values())\n",
    "    for value_label in undefined_set:\n",
    "        if value_label in vls:\n",
    "            print(filename + ' ' + str(value_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a206569",
   "metadata": {},
   "source": [
    "This makes sense. For some reason `kmri_sq_worms` has its own catalog file. Who knows what is going on with the `sageancillarystudy`? Ignoring for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b4712b",
   "metadata": {},
   "source": [
    "### Look closer at NaN keys\n",
    "This is a side-effect of pyreadstat, not SAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2823820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for dictionaries with more than one NaN entry.\n",
    "for k1, v1 in local_cat.value_labels.items():\n",
    "    v1_klist = [k for k in v1.keys()]\n",
    "    cnt = 0    \n",
    "    for k2 in v1_klist:\n",
    "        if isinstance(k2, float) and math.isnan(k2):\n",
    "            cnt += 1\n",
    "    if cnt > 1:\n",
    "        print(\"Duplicate NaN keys in dict: \" + k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ae215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if the count differs for the second catalog\n",
    "for k1, v1 in pdf_cat.value_labels.items():\n",
    "    v1_klist = [k for k in v1.keys()]\n",
    "    cnt = 0    \n",
    "    for k2 in v1_klist:\n",
    "        if isinstance(k2, float) and math.isnan(k2):\n",
    "            cnt += 1\n",
    "    if cnt > 1:\n",
    "        print(\"Duplicate NaN keys in dict: \" + k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb742d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When two NaNs occur, what are the values?\n",
    "for k1, v1 in local_cat.value_labels.items():\n",
    "    # Get both sub dictionaries\n",
    "    v1_list = [(k,v) for k,v in v1.items()]\n",
    "    \n",
    "    cnt = 0\n",
    "    last_val = ''\n",
    "    for (k2, v2) in v1_list:\n",
    "        if isinstance(k2, float) and math.isnan(k2):\n",
    "            cnt += 1\n",
    "            if cnt > 1:\n",
    "                print(k1 + ': ' + last_val + '\\t' + v2)\n",
    "            last_val = v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf76566",
   "metadata": {},
   "source": [
    "The duplicates seem to be a parsing issue, not two values that parse two NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ae754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many value labels contain one or more NaNs?\n",
    "cnt = 0    \n",
    "for k1, v1 in local_cat.value_labels.items():\n",
    "    v1_klist = [k for k in v1.keys()]\n",
    "    for k2 in v1_klist:\n",
    "        if isinstance(k2, float) and math.isnan(k2):\n",
    "            cnt += 1\n",
    "            break\n",
    "print(\"Dicts: \" + str(len(local_cat.value_labels)) + '\\tDicts w/ NaNs: ' + str(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b84e83b",
   "metadata": {},
   "source": [
    "Seems that NaN's are common."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e483ab",
   "metadata": {},
   "source": [
    "## Explore optimal pyreadstat settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cbb6b2",
   "metadata": {},
   "source": [
    "Look at how various pyreadstat flags interact with this particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf37192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a small sample dataset with mixed types (including user defined types)\n",
    "# Parse with only catalog files\n",
    "filename = 'kmri_sq_blksbml_bicl03.sas7bdat'\n",
    "df1, meta = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename,\n",
    "                                                         catalog_file=data_dir + 'formats.sas7bcat',\n",
    "                                                         num_processes=6)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ccdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at what types pyreadstat chose with a provided catalog file\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6789c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that two columns share a user defined type\n",
    "files_meta[filename].variable_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What possible values?\n",
    "local_cat.value_labels['BBMLSPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.V03BBMLP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece69825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many NaN values\n",
    "df1.V03BBMLP.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse with catalog files and user_missing=True\n",
    "df2, meta2 = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename,\n",
    "                                                         catalog_file=data_dir + 'formats.sas7bcat',\n",
    "                                                         num_processes=6, user_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.V03BBMLP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38aadaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.V03BBMLP.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef3b7d",
   "metadata": {},
   "source": [
    "This only leaves the NaNs to be cconverted to the user defined categorical.  It seems pyreadstat parses . as NaN, but only connects NaN to a value label in the value label table. In the actual data it remains a NaN. This could be confusing if NaNs exist in the data for other reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5342d1a",
   "metadata": {},
   "source": [
    "### Looking at dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse with catalog files and user_missing=True and dates_as_pandas_datetime=True\n",
    "filename = 'outcomes99.sas7bdat'\n",
    "df3, meta3 = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename,\n",
    "                                                         catalog_file=data_dir + 'formats.sas7bcat',\n",
    "                                                         num_processes=6, dates_as_pandas_datetime=True, user_missing=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51135ed1",
   "metadata": {},
   "source": [
    "* No flags: date columns are mixed objects: NaN (float) and Python datatime.date objects\n",
    "* If dates_as_pandas_datetime=True, then columns become Pandas.datetimens[64]\n",
    "* If dates_as_pandas_datetime=True and user_missing=True, get a mixed objects: str and datetime.datetime objects (note strs are missing data flags without the starting .)\n",
    "\n",
    "In a system in like Pandas you can't combine multiple missing value types with other datatypes. In this case, only one missing value type is used (.A) but that isn't guaranteed for all dates. If this is the only missing value flag, it can be noted in comments that NaT = .A, and all date columns can be converted to Pandas datetime columns.  While this example only shows it in relation to dates, but it could also apply to numeric columns, with more missing types being used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8784aba4",
   "metadata": {},
   "source": [
    "### How many variables don't have set categories?\n",
    "Both dates and numeric value columns will need closer inspection to store them well.  How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd834579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many variables don't have a set data format?\n",
    "var_cnt = 0\n",
    "null_cnt = 0\n",
    "date_cnt = 0\n",
    "for filename, meta in files_meta.items():\n",
    "    var_cnt += len(meta.original_variable_types.keys())\n",
    "    null_cnt += len([n for n in meta.original_variable_types.values() if n == 'NULL'])\n",
    "    date_cnt += len([n for n in meta.original_variable_types.values() if n == 'MMDDYY'])\n",
    "print('Total variables stored: ' + str(var_cnt))\n",
    "print('Null variables stored: ' + str(null_cnt))\n",
    "print('Date variables stored: ' + str(date_cnt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "695px",
    "left": "2640px",
    "right": "20px",
    "top": "120px",
    "width": "311px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
