{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a755df56",
   "metadata": {},
   "source": [
    "# Exploring SAS file metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a64c27",
   "metadata": {},
   "source": [
    "Anyone working with the OAI structured data has a choice, import the data from ASCII or SAS. This project chooses to rely on the SAS data. There are over 13,000 different variables recorded by OAI.  Writing heuristics to guess the optimal data types for all 13,000 is likely to be more flawed than leveraging what we can from SAS metadata. This notebook explores what SAS metadata can be pulled out by pyreadstat (there may be metadata it ignores; I haven't verified it's code). It is mostly here as a record of discovery and not typically needed for anyone looking to jump into the data.\n",
    "\n",
    "The data seems to be stored in two ways:\n",
    "* A collection of sas7bdat and sas7bcat files.\n",
    "* In the SAS propietary CPORT format (labeled .xpt instead of .cpt)\n",
    "\n",
    "Thanks to the OAI employee who chose to support a closed source, proprietary format. While SAS was common enough in 2012, chosing proprietary formats for govt. owned data was already bad form by then. Further, the files are listed as .XPT files just to keep users confused (you can find users trying to solve this mystery for this exact dataset in internet forums).  Not having a SAS instance, we have to ignore the the CPORT files and hope no information is lost in doing so. It isn't also clear why the data is saved in a compressed format (save space) but also bundled with a non-compressed form (benefits of compression lost). Maybe historical reasons.\n",
    "\n",
    "**Main Explorations:**\n",
    "* What is present in the OAI metadata?\n",
    "* What is and isn't consistent?\n",
    "  * Good data design doesn't repeat values since that just opens the door inconsistency. This data has lots of repeated data. Some of this what OAI released and though repeats in the metadata may be how pyreadstat saves the data it reads.\n",
    "\n",
    "All statistical platforms have their design pro's and con's. An excellent benefit of SAS is that it allows for multiple different markers for missing values. This is probably the largest issue in translating from SAS to Pandas.  Much of this notebook examines  \n",
    "\n",
    "Subtle details may change between OAI release versions. Thus, once facts are established, they are encoded as assertions that can be verified when a new version of the data is released."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9ea12f",
   "metadata": {},
   "source": [
    "## Setup / Imports / Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7cf801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyreadstat\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "data_dir = '../data/structured_data/'\n",
    "pdfs_dir = '../data/pdfs/General/Formats_SAS/'\n",
    "\n",
    "visit_prefixes = {'P02':'IEI', 'P01':'SV', 'V00':'EV', 'V01':'12m', 'V02':'18m', 'V03':'24m', 'V04':'30m', 'V05':'36m',\n",
    "          'V06':'48m', 'V07':'60m', 'V08':'72m', 'V09':'84m', 'V10':'96m', 'V11':'108m', 'V99':\"Outcomes\"}\n",
    "visit_prefixes = set(visit_prefixes.keys())\n",
    "\n",
    "# Metadata values pulled out by pyreadstat\n",
    "meta_vars = [ 'column_labels',\n",
    " 'column_names',\n",
    " 'column_names_to_labels',\n",
    " 'file_encoding',\n",
    " 'file_format',\n",
    " 'file_label',\n",
    " 'missing_ranges',\n",
    " 'missing_user_values',\n",
    " 'notes',\n",
    " 'number_columns',\n",
    " 'number_rows',\n",
    " 'original_variable_types',\n",
    " 'readstat_variable_types',\n",
    " 'table_name',\n",
    " 'value_labels',\n",
    " 'variable_alignment',\n",
    " 'variable_display_width',\n",
    " 'variable_measure',\n",
    " 'variable_storage_width',\n",
    " 'variable_to_label',\n",
    " 'variable_value_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd56fc",
   "metadata": {},
   "source": [
    "## Read in all metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e296209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All SAS files\n",
    "all_files = os.listdir(data_dir)\n",
    "all_files = [x for x in all_files if '.sas7bdat' in x]\n",
    "all_files.remove('sageancillarystudy_formats.sas7bdat') ## At a binary level this seems like another CPORT file. WTF?\n",
    "all_files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60faaa74",
   "metadata": {},
   "source": [
    "It seems that between the sas7bdat files and the sas7bcat files, almost all metadata is stored in the sas7bdat along with the actual data. The only metadata that seems to be provided by `formats.sas7bcat` is value_labels: a dictionary of value maps. We will read that in later, but for now lets look at the main metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roughly ~1.5 min runtime\n",
    "files_meta = {}\n",
    "for filename in all_files:\n",
    "    _, meta = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename,\n",
    "                                                         num_processes=6, metadataonly=True)\n",
    "    files_meta[filename] = meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27350d9",
   "metadata": {},
   "source": [
    "### See what metadata variable values are common across all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what metadata is collected across all files\n",
    "# if a single value, list it.\n",
    "# if a collection store the collection size for this file\n",
    "\n",
    "# create storage dict\n",
    "meta_dict = {v: [] for v in meta_vars}\n",
    "meta_dict['Filename'] = []\n",
    "\n",
    "for filename, meta in files_meta.items():\n",
    "    meta_dict['Filename'].append(filename)\n",
    "\n",
    "    for mv in meta_vars:\n",
    "        var = getattr(meta, mv)\n",
    "        if var:\n",
    "            if isinstance(var, int):\n",
    "                meta_dict[mv].append(var)\n",
    "            elif isinstance(var, str):\n",
    "                meta_dict[mv].append(var)\n",
    "            else:\n",
    "                meta_dict[mv].append(len(var))\n",
    "        else:\n",
    "             meta_dict[mv].append(None)\n",
    "\n",
    "tmp_df = pd.DataFrame(meta_dict).set_index('Filename')\n",
    "meta_dict = None\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bf310b",
   "metadata": {},
   "source": [
    "**Vocab**\n",
    "\n",
    "I don't know if columns can have different names than variables, but they don't seem to in this dataset. As far as this data is concerned `column_names` == `variables_names`.\n",
    "\n",
    "Note that two kinds of labels exist: variable and value. The former is prose describing a variable. The latter is user defined type in SAS; similar to a CategoricalDtype in Pandas. A single value label is a named dict mapping the stored values in a column to more verbose categories. This can be categorical values that cover all values in a collumn, or they can just be a set of missing value labels (e.g. ).\n",
    "\n",
    "* column_names: Seems to be the same as variable names\n",
    "* column_labels: Brief prose descriptions of what a variable records\n",
    "* column_names_to_labels: A dict of column names to column labels\n",
    "* file_encoding: Character encoding of stored strings\n",
    "* file_format: The storage format\n",
    "* file_label:\n",
    "* missing_ranges: I believe this only applies to SPSS files\n",
    "* missing_user_values: A dict that maps variable names to a list of character values (A to Z and _ for SAS) representing user defined missing values in SAS\n",
    "* notes: \n",
    "* number_columns:\n",
    "* number_rows: Number of rows of data\n",
    "* original_variable_types:  A dict that maps variable names to the name of a data type. This could be the name of a SAS native data type, like `$` (meaning string values) or a user defined type (which are stored in the `value_labels` dict (e.g. GENDER, or RACE)). In some cases, this is like a map from variable name to the name of CategoricalDtype objects. In other cases, the majority of the data is a native data type but the named data type is merely a map of what characters are used to denote a missing value in that column. This would be like having a column of numbers in Pandas with categorical values mixed in for missing values. If a variable was not assigned a named data type, the value NULL is given.\n",
    "* readstat_variable_types: Within the data files, I believe columns are either strings or doubles (numeric in SAS). Note that even if stored primarily as a double, character strings may be mixed in to represent missing values\n",
    "* table_name: Not sure if this is useful in any way\n",
    "* value_labels: Not provided by sas7bdat, the master value_label dict is in `formats.sas7bcat`. It is a dict of dicts. The top level dict maps a `value_label` name to a dict that translates column values into categorical values (sometimes just a translation of the different missing values types).\n",
    "* variable_alignment: A dict mapping variable names to a display alignment: left, center, right or unknown\n",
    "* variable_display_width: A dict mapping variable names to the display width in SAS\n",
    "* variable_measure: A dict mapping variable names to a description of the measure: nominal, ordinal, scale or unknown\n",
    "* variable_storage_width: A dict mapping variable names to a storage width\n",
    "* variable_to_label: Holds the same values as original_variable_types, except that variables without an assigned data type are left out of this dict rather than assigned NULL.\n",
    "* variable_value_labels: A dict mapping variable names directly to the appropriate `value_label` data type map. Empty unless a sas7bcat was given. It is a combination of value_labels and variable_to_label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks on columns that should all have the same number of values and same keys in their dicts\n",
    "# - failure means the data (or pyreaadstat) has changed since this was written\n",
    "for file, meta in files_meta.items():\n",
    "    assert meta.number_columns == len(meta.column_labels)\n",
    "    assert meta.number_columns == len(meta.column_names)\n",
    "    # Do column_names + column_labels = column_names_to_labels?\n",
    "    assert set(meta.column_labels) == set(meta.column_names_to_labels.values())\n",
    "    \n",
    "    # Do all variables match a column name?\n",
    "    names = set(meta.column_names)\n",
    "    assert len(names ^ set(meta.column_names_to_labels.keys())) == 0\n",
    "    assert len(names ^ set(meta.original_variable_types.keys())) == 0\n",
    "    assert len(names ^ set(meta.readstat_variable_types.keys())) == 0\n",
    "    assert len(names ^ set(meta.variable_alignment.keys())) == 0\n",
    "    assert len(names ^ set(meta.variable_display_width.keys())) == 0\n",
    "    assert len(names ^ set(meta.variable_storage_width.keys())) == 0\n",
    "    assert names >= set(meta.variable_to_label.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babbdb5f",
   "metadata": {},
   "source": [
    "#### Empty metadata variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List metadata variables which are empty for all files\n",
    "\n",
    "print(str(list(tmp_df.columns[tmp_df.isna().all()].sort_values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a3836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# - failure means the data (or pyreaadstat) has changed since this was written\n",
    "empty_vars = ['missing_ranges', 'missing_user_values', 'notes', 'value_labels', 'variable_value_labels']\n",
    "for var in empty_vars:\n",
    "    assert tmp_df[var].isna().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018f870",
   "metadata": {},
   "source": [
    "#### Partially populated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns have an occasional empty value?\n",
    "incomplete = set(tmp_df.columns[tmp_df.isna().any()]) - set(tmp_df.columns[tmp_df.isna().all()])\n",
    "for x in incomplete:\n",
    "    print(x + ': ' + str(tmp_df[x].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d2380e",
   "metadata": {},
   "source": [
    "#### Constant values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f6835",
   "metadata": {},
   "source": [
    "So `file_encoding`, `file_format` are the same across all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4533643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# - failure means the data (or pyreaadstat) has changed since this was written\n",
    "assert len(list(tmp_df['file_encoding'].unique())) == 1\n",
    "assert list(tmp_df['file_encoding'].unique())[0] == 'WINDOWS-1252'\n",
    "assert len(list(tmp_df['file_format'].unique())) == 1\n",
    "assert list(tmp_df['file_format'].unique())[0] == 'sas7bdat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91783f3c",
   "metadata": {},
   "source": [
    "#### Unique values across all metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9232e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the unique values occur for given variable dictionaries\n",
    "col_list = ['original_variable_types', 'readstat_variable_types', 'variable_alignment', 'variable_display_width', 'variable_measure', 'variable_storage_width', 'variable_to_label']\n",
    "\n",
    "col_sets = {c: set() for c in col_list}\n",
    "for file, meta in files_meta.items():\n",
    "    for col in col_list:\n",
    "        var = getattr(meta, col)\n",
    "        if var:\n",
    "            if isinstance(var, dict):\n",
    "                col_sets[col].update(var.values())\n",
    "            else:\n",
    "                col_sets[col].update(var)\n",
    "                \n",
    "for col, vals in col_sets.items():\n",
    "    print(col + '(' + str(len(vals)) + '): ' + str(list(vals)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859f9dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sets['original_variable_types'] - col_sets['variable_to_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389a399",
   "metadata": {},
   "source": [
    "So it seems that only `original_variable_types`, `variable_storage_width`, `variable_to_label` have anything unique to say about a variable (aside from variable/column names and labels). As shown several cells above, `original_variable_types` has a dict value for every variable (even if that value is `NULL`). `variable_to_label` seems to have the same data, but leaves out variables that don't use a value list. 'Value labels' seem to be SAS's form of user defined formats ( https://libguides.library.kent.edu/SAS/UserDefinedFormats ), somewhat like categories in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "# - failure means the data (or pyreaadstat) has changed since this was written\n",
    "assert col_sets['readstat_variable_types'] == {'double', 'string'}\n",
    "assert col_sets['variable_alignment'] == {'unknown'}\n",
    "assert col_sets['variable_display_width'] == {0}\n",
    "assert col_sets['variable_measure'] == {'unknown'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24b2ed",
   "metadata": {},
   "source": [
    "## Check for differences in format files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5747f01c",
   "metadata": {},
   "source": [
    "There seem to be two competing SAS catalog files*:\n",
    "* `../data/pdfs/General/Formats_SAS/formats.sas7bcat`\n",
    "* `../data/structured_data/formats.sas7bcat`\n",
    "\n",
    "At a binary level, they are different, let's look at them as far as pyreadstat can determine. \n",
    "\n",
    "*(Ignoring the `kMRI_SQ_WORMS_Link_Formats.sas7bcat` file for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, local_cat = pyreadstat.read_sas7bcat(data_dir + 'formats.sas7bcat')\n",
    "_, pdf_cat = pyreadstat.read_sas7bcat(pdfs_dir + 'formats.sas7bcat')\n",
    "\n",
    "for cat in [local_cat, pdf_cat]:\n",
    "    for v in meta_vars:\n",
    "        var = getattr(cat,v)\n",
    "        if var:\n",
    "            if isinstance(var, int):\n",
    "                print(v + ': ' + str(var))\n",
    "            else:\n",
    "                print(v + ' - ' + str(len(var)))\n",
    "        else:\n",
    "            print(v + ' - empty')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb11abf0",
   "metadata": {},
   "source": [
    "They seem the same. Both only contain 'value_labels' a dict mapping data type names to dicts defining those data types. Confirm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5a9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the dicts of the local catalog vs the one in the pdfs dir\n",
    "# - each is a dict of value dicts\n",
    "# - this is more code than normally needed because pyreadstat is creating NaN keys\n",
    "\n",
    "# At the top level, both have the same keys\n",
    "assert set(local_cat.value_labels.keys()) == set(pdf_cat.value_labels.keys())\n",
    "\n",
    "for k1, v1 in local_cat.value_labels.items():\n",
    "    # Get both sub dictionaries\n",
    "    v1_list = [(k,v) for k,v in v1.items()]\n",
    "    pdf_v1_list = [(k,v) for k,v in pdf_cat.value_labels[k1].items()]\n",
    "        \n",
    "    for (k2, v2) in v1_list:\n",
    "        # Confirm match exists\n",
    "        key_match = False\n",
    "        for (pdf_k2, pdf_v2) in pdf_v1_list:\n",
    "            if pdf_k2 == k2 or (isinstance(k2, float) and math.isnan(k2) and math.isnan(pdf_k2)):\n",
    "                key_match = True\n",
    "                if pdf_v2 == v2:\n",
    "                    break\n",
    "                else:\n",
    "                    # Mis-match on sub-dict values\n",
    "                    print('Dict[' + str(k1) + '][' + str(k2) + ']: [local v: ' + v2 + ']\\t[pdf v: ' + pdf_v2 + ']')\n",
    "                    break\n",
    "        if not key_match:\n",
    "            print('Dict[' + str(k1) + '): [local k: ' + str(k2) + ' had no match in: ' +  str([k for (k,v) in pdf_v1_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the order see if any keys exist in the PDF versions that don't exist in the local catalog files\n",
    "for k1, v1 in pdf_cat.value_labels.items():\n",
    "    # Get both sub dictionaries\n",
    "    v1_list = [(k,v) for k,v in v1.items()]\n",
    "    local_v1_list = [(k,v) for k,v in local_cat.value_labels[k1].items()]\n",
    "        \n",
    "    for (k2, v2) in v1_list:\n",
    "        # Confirm match exists\n",
    "        key_match = False\n",
    "        for (local_k2, local_v2) in local_v1_list:\n",
    "            if local_k2 == k2 or (isinstance(k2, float) and math.isnan(k2) and math.isnan(local_k2)):\n",
    "                key_match = True\n",
    "                if local_v2 == v2:\n",
    "                    break\n",
    "        if not key_match:\n",
    "            print('Dict[' + str(k1) + '): [pdf k: ' + str(k2) + ' had no match in: ' +  str([k for (k,v) in local_v1_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a1b203",
   "metadata": {},
   "source": [
    "**Great**. They aren't the same. So two keys shipped with the data aren't in the catalog file shipped with the PDFs. Seven values seem to have minor differences in their label text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are any of the conflicting value dicts present in this data set?\n",
    "conflicting_value_labels = {'$SYNACCP', 'WTCHG', 'CRTMRPH', 'MMMRPH'}\n",
    "col_sets['variable_to_label']\n",
    "\n",
    "print(conflicting_value_labels & col_sets['variable_to_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501a58e",
   "metadata": {},
   "source": [
    "It seems like they are all used, so the point isn't exactly moot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad086a2",
   "metadata": {},
   "source": [
    "### Undefined data formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468a65df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are their any variable types that aren't user defined?\n",
    "undefined_set = col_sets['variable_to_label'] - set(local_cat.value_labels.keys())\n",
    "print(undefined_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61551227",
   "metadata": {},
   "source": [
    "* $ in SAS means character data\n",
    "* BEST is numeric data that lets the system chose the best display format\n",
    "* MMDDYY is obviously a date\n",
    "\n",
    "I haven't found documentation for the rest ( https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.5/leforinforref/p0z62k899n6a7wn1r5in6q5253v1.htm ). Formats whose definitions weren't exported?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562db93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which data sets contain these undefined formats\n",
    "undefined_set.remove('$')\n",
    "undefined_set.remove('BEST')\n",
    "undefined_set.remove('MMDDYY')\n",
    "\n",
    "\n",
    "for filename, meta in files_meta.items():\n",
    "    vls = set(meta.variable_to_label.values())\n",
    "    for value_label in undefined_set:\n",
    "        if value_label in vls:\n",
    "            print(filename + ' ' + str(value_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a206569",
   "metadata": {},
   "source": [
    "This makes sense. For some reason `kmri_sq_worms` has its own catalog file. Who knows what is going on with the `sageancillarystudy`? Ignoring for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b4712b",
   "metadata": {},
   "source": [
    "### Look closer at NaN keys\n",
    "Since NaN does not equal NaN, they should never be made a key in a Python dictionary. Yet, the `value_label` dictionaries returned from pyreadstat has them. Further, a Python dictionary cannot have two copies of the same key, and yet we have that here as well. This seems like a side-effect of pyreadstat, not SAS. This looks at the extent of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2823820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for dictionaries with more than one NaN entry.\n",
    "for vl_name, vl_dict in local_cat.value_labels.items():\n",
    "    v1_klist = [k for k in vl_dict.keys()]\n",
    "    cnt = 0    \n",
    "    for key in v1_klist:\n",
    "        if isinstance(key, float) and math.isnan(key):\n",
    "            cnt += 1\n",
    "    if cnt > 1:\n",
    "        print(\"Duplicate NaN keys in value label: \" + vl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ae215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if the count differs for the second catalog\n",
    "for vl_name, vl_dict in pdf_cat.value_labels.items():\n",
    "    v1_klist = [k for k in vl_dict.keys()]\n",
    "    cnt = 0    \n",
    "    for key in v1_klist:\n",
    "        if isinstance(key, float) and math.isnan(key):\n",
    "            cnt += 1\n",
    "    if cnt > 1:\n",
    "        print(\"Duplicate NaN keys in value label: \" + vl_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb742d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When two NaNs occur, what are the values?\n",
    "for k1, v1 in local_cat.value_labels.items():\n",
    "    # Get both sub dictionaries\n",
    "    v1_list = [(k,v) for k,v in v1.items()]\n",
    "    \n",
    "    cnt = 0\n",
    "    last_val = ''\n",
    "    for (k2, v2) in v1_list:\n",
    "        if isinstance(k2, float) and math.isnan(k2):\n",
    "            cnt += 1\n",
    "            if cnt > 1:\n",
    "                print(k1 + ': \\t' + last_val + '\\t' + v2)\n",
    "            last_val = v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf76566",
   "metadata": {},
   "source": [
    "The duplicates seem to be a parsing issue, not two values that parse two NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ae754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many value labels contain one or more NaNs?\n",
    "cnt = 0    \n",
    "for v1_dict in local_cat.value_labels.values():\n",
    "    v1_klist = [k for k in v1_dict.keys()]\n",
    "    for key in v1_klist:\n",
    "        if isinstance(key, float) and math.isnan(key):\n",
    "            cnt += 1\n",
    "            break\n",
    "print(\"Dicts: \" + str(len(local_cat.value_labels)) + '\\tDicts w/ NaNs: ' + str(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b84e83b",
   "metadata": {},
   "source": [
    "Seems that NaN's are common."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5dcc1d",
   "metadata": {},
   "source": [
    "### Double check missing value marker\n",
    "In SAS, '.' is the default marker for a missing value in a numeric column and ' ' for string columns. Since both seem to have been converted to NaN's, lets make sure all the value label dictionarys reflect this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6cc3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37e483ab",
   "metadata": {},
   "source": [
    "## Explore optimal pyreadstat settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cbb6b2",
   "metadata": {},
   "source": [
    "Look at how various pyreadstat flags interact with this particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf37192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a small sample dataset with mixed types (including user defined types)\n",
    "# Parse with only catalog file\n",
    "filename = 'kmri_sq_blksbml_bicl03.sas7bdat'\n",
    "df1, meta1 = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename,\n",
    "                                                         catalog_file=data_dir + 'formats.sas7bcat',\n",
    "                                                         num_processes=6)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df507e0",
   "metadata": {},
   "source": [
    "### Look at metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What metadata is present when a catalog file is included?\n",
    "for v in meta_vars:\n",
    "    var = getattr(meta1,v)\n",
    "    if var:\n",
    "        if isinstance(var, int):\n",
    "            print(v + ': ' + str(var))\n",
    "        else:\n",
    "            print(v + ' - ' + str(len(var)))\n",
    "    else:\n",
    "        print(v + ' - empty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539c3294",
   "metadata": {},
   "source": [
    "It seems that the user defined values (`value_labels`) have been inserted into the data, but not stored in the metadata dict. `variable_value_labels` is also empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5ccdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at what types pyreadstat chose with a provided catalog file\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337929e",
   "metadata": {},
   "source": [
    "### Look at categories/value labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef69a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that two columns share a user defined type (they should according to documentation)\n",
    "meta1.variable_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at an example\n",
    "df1.V03BBMLP.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b2664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.V03BBMLP.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What possible values?\n",
    "local_cat.value_labels['BBMLSPE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c7f3f7",
   "metadata": {},
   "source": [
    "Looks like the pystatreader is only casting the column to categorical, not setting the category types via `value_labels` data (Confirmed looking at the code base). This means that the same variable captured across two different visit may have different categorical types (since some values may be present only in one visit set and not another)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a649ff6",
   "metadata": {},
   "source": [
    "### Look at NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece69825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many NaN values\n",
    "df1.V03BBMLP.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49d1965",
   "metadata": {},
   "source": [
    "### Try setting user_missing=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse with catalog files and user_missing=True\n",
    "df2, meta2 = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename,\n",
    "                                                         catalog_file=data_dir + 'formats.sas7bcat',\n",
    "                                                         num_processes=6, user_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38aadaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.V03BBMLP.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.V03BBMLP.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef3b7d",
   "metadata": {},
   "source": [
    "This only leaves the NaNs to be cconverted to the user defined categorical.  It seems pyreadstat parses . as NaN, but only connects NaN to a value label in the value label table. In the actual data it remains a NaN. This could be confusing if NaNs exist in the data for other reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910e1a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What metadata is present when a catalog file is included?\n",
    "for v in meta_vars:\n",
    "    var = getattr(meta2,v)\n",
    "    if var:\n",
    "        if isinstance(var, int):\n",
    "            print(v + ': ' + str(var))\n",
    "        else:\n",
    "            print(v + ' - ' + str(len(var)))\n",
    "    else:\n",
    "        print(v + ' - empty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8091db09",
   "metadata": {},
   "source": [
    "`value_labels` and `variable_value_labels` are still empty. So is `missing_ranges` and `missing_user_values`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5342d1a",
   "metadata": {},
   "source": [
    "### Looking at dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse with catalog files and user_missing=True and dates_as_pandas_datetime=True\n",
    "filename = 'outcomes99.sas7bdat'\n",
    "df3, meta3 = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename,\n",
    "                                                         catalog_file=data_dir + 'formats.sas7bcat',\n",
    "                                                         num_processes=6, dates_as_pandas_datetime=True, user_missing=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51135ed1",
   "metadata": {},
   "source": [
    "* No flags: date columns are mixed objects: NaN (float) and Python datatime.date objects\n",
    "* If dates_as_pandas_datetime=True, then columns become Pandas.datetimens[64]\n",
    "* If dates_as_pandas_datetime=True and user_missing=True, get a mixed objects: str and datetime.datetime objects. \n",
    "\n",
    "In ths case, the string in a date column is the char `A`. In the pyreadstat code, only columns with user defined data type have signal characters like `A` converted to their verbose form (e.g. `A: Not Expected`). This will likely happen for the other columns that use SAS native data types.\n",
    "\n",
    "In a system like Pandas you can't combine multiple missing value types with other datatypes without getting a mixed type column (less efficient and prevents some column wide actions). In this case, only one missing value type is used (.A) but that isn't guaranteed for all dates. If this is the only missing value flag, it can be noted in comments that NaT = .A, and all date columns can be converted to Pandas datetime columns.  While this example only shows it in relation to dates, but it could also apply to numeric columns, with more missing types being used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8784aba4",
   "metadata": {},
   "source": [
    "### How many variables don't have set categories?\n",
    "Both dates and numeric value columns will need closer inspection to store them well.  How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd834579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many variables don't have a user-defined data format?\n",
    "var_cnt = 0\n",
    "null_cnt = 0\n",
    "date_cnt = 0\n",
    "best_cnt = 0\n",
    "str_cnt = 0\n",
    "for filename, meta in files_meta.items():\n",
    "    var_cnt += len(meta.original_variable_types.keys())\n",
    "    null_cnt += len([n for n in meta.original_variable_types.values() if n == 'NULL'])\n",
    "    date_cnt += len([n for n in meta.original_variable_types.values() if n == 'MMDDYY'])\n",
    "    best_cnt += len([n for n in meta.original_variable_types.values() if n == 'BEST'])\n",
    "    str_cnt += len([n for n in meta.original_variable_types.values() if n == '$'])\n",
    "print('Total variables stored: ' + str(var_cnt))\n",
    "print('NULL variables stored: ' + str(null_cnt))\n",
    "print('Date (MMDDYY) variables stored: ' + str(date_cnt))\n",
    "print('Numeric (BEST) variables stored: ' + str(best_cnt))\n",
    "print('String variables stored: ' + str(str_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17075ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of those undefined types (NULL) are string vs numeric\n",
    "null_str_cnt = 0\n",
    "null_dbl_cnt = 0\n",
    "for filename, meta in files_meta.items():\n",
    "    for var_name, data_type in meta.original_variable_types.items():\n",
    "        if data_type == 'NULL':\n",
    "            storage_type = meta.readstat_variable_types[var_name]\n",
    "            if storage_type == 'string':\n",
    "                null_str_cnt += 1\n",
    "            else:  # double\n",
    "                null_dbl_cnt += 1\n",
    "print('NULL - string variables stored: ' + str(null_str_cnt))\n",
    "print('NULL - numeric variables stored: ' + str(null_dbl_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3792be19",
   "metadata": {},
   "source": [
    "## Missing data without a catalog file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98099b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'kmri_sq_blksbml_bicl03.sas7bdat'\n",
    "df1, meta = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename,\n",
    "                                                         catalog_file=data_dir + 'formats.sas7bcat',\n",
    "                                                         num_processes=6, user_missing=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b82018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8abc994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2, meta = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename, num_processes=6, user_missing=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cfc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94650df8",
   "metadata": {},
   "source": [
    "The absence of category columns is expected. Are the number of NaNs sensible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.V03BBMLP.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the number of NaNs is the same for every column\n",
    "for col in df1.columns:\n",
    "    cat_col_uni = len(df1[col].unique())\n",
    "    col_uni = len(df2[col].unique())\n",
    "    if cat_col_uni != col_uni:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d79de4b",
   "metadata": {},
   "source": [
    "In both cases, the number of NaNs is what we expect. What does the data look like? Presumably mixed type columns? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1['V03BBMLP'].unique())\n",
    "print(df2['V03BBMLP'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb5bc3",
   "metadata": {},
   "source": [
    "Yes. This could be useful. user_missing=True doeesn't depend on catalog data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3885565a",
   "metadata": {},
   "source": [
    "## Look at names with prefix\n",
    "\n",
    "For many files looked at so far, only `ID` and `VERSION` variables lack a visit prefix. Is this true across all files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cec2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab all variable names\n",
    "all_var_names = []\n",
    "for meta in files_meta.values():\n",
    "    tmp = [(str.upper(var), filename) for var in meta.column_names]\n",
    "    all_var_names.extend(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a247aa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total cnt of variables across files: ' + str(len(all_var_names)))\n",
    "\n",
    "cnt = 0\n",
    "no_prefix = set()\n",
    "for (name, _) in all_var_names:\n",
    "    if name[:3] not in visit_prefixes:\n",
    "        cnt += 1\n",
    "        no_prefix.add(name) \n",
    "print('Variable cnt w/out prefix: ' + str(cnt))\n",
    "print('Unique variable names without a prefix: ' + str(len(no_prefix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20335083",
   "metadata": {},
   "source": [
    "## Which Variable Names Are Reused Across Files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac849ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many variable names are reused across datafiles?\n",
    "avn_ser = pd.DataFrame(all_var_names, columns =['Var', 'File'])\n",
    "cnts = avn_ser.Var.value_counts(ascending=True)\n",
    "cnts[cnts > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f0113",
   "metadata": {},
   "source": [
    "VERSION seems to exist in every file, and ID in all but two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7144b22c",
   "metadata": {},
   "source": [
    "### Which files lack an ID variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c0d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which files lack an ID field?\n",
    "for file, meta in files_meta.items():\n",
    "    if not {'ID', 'id', 'Id'} & set(meta.column_names):\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d29ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files_meta['Biospec_fnih_joco_demographics.sas7bdat'].column_names)\n",
    "print(files_meta['biospec_fnih_joco_assays.sas7bdat'].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9361a9f",
   "metadata": {},
   "source": [
    "### Looking at files that reuse variable names\n",
    "The reuse of names like `SIDE` isn't concerning. However, the number of variables with a prefix that are being used is. This is repeating data. This requires sanity checks to ensure the values are the same in both locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792c1fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What files are various repeated variables used in?\n",
    "subset = avn_ser[avn_ser.Var.isin(list(cnts[cnts > 1].index))]\n",
    "var_dict = {}\n",
    "for var, file in subset.to_records(index=False):\n",
    "    if var_dict.get(var):\n",
    "        var_dict[var].append(file)\n",
    "    else:\n",
    "        var_dict[var] = [file]\n",
    "\n",
    "ignore = ['ID', 'VERSION']\n",
    "total_file_set = set()\n",
    "for k,v in var_dict.items():\n",
    "    if k not in ignore:\n",
    "        print(k + '(' + str(len(v))+'): ' + str(v))\n",
    "        total_file_set.update(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9211fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_file_set = list(total_file_set)\n",
    "total_file_set.sort()\n",
    "total_file_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What files use variables that don't have a prefix AND are part of a fileset\n",
    "file_set = set()\n",
    "for var in no_prefix:\n",
    "    if var not in ignore:\n",
    "        file_list = []\n",
    "        for (name, fname) in all_var_names:\n",
    "            if var == name:\n",
    "                file_list.append(fname)\n",
    "                file_set.add(fname)\n",
    "        # fileset check\n",
    "        fileset = False\n",
    "        for f in file_list:\n",
    "            if re.match(\"\\S*\\d\\d\\.sas7bdat\", f):\n",
    "                fileset = True\n",
    "        if fileset:\n",
    "            print(var + '(' + str(len(file_list)) + ')'': ' + str(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = list(file_set)\n",
    "file_list.sort()\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45717dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408209f5",
   "metadata": {},
   "source": [
    "## Variable names across files\n",
    "When concatentating files across visits, for now, the code is easiest if `ID` and `VERSION` are the only two variables that lacka a visit pre-fix. Which files does this apply to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcf903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which files have all a visit prefix for all variables\n",
    "cnt = 0\n",
    "for file, meta in files_meta.items():\n",
    "    cols = [n.upper() for n in meta.column_names]\n",
    "    if 'ID' in cols:\n",
    "        cols.remove('ID')\n",
    "    cols.remove('VERSION')\n",
    "    all_visit_prefix = True\n",
    "    for col in cols:\n",
    "        if col[:3] not in visit_prefixes:\n",
    "            all_visit_prefix = False\n",
    "    if all_visit_prefix:\n",
    "        print(file)\n",
    "        cnt += 1\n",
    "print(cnt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b3116",
   "metadata": {},
   "source": [
    "## Are value_ labels Consistent Across Visits?\n",
    "If we drop the visit prefixes, does the same variable have the same value label across visits? This will be important if we concatenate dataframes across visits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b86ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through all variable names, get their the name of their value_label, drop their prefix, and build a dict mapping variable names without a prefix to a list of all the value_labels assigned to any variable sharing the same prefix-free name\n",
    "val_label_dict = {}\n",
    "for file, meta in files_meta.items():\n",
    "    for var_name, val_lbl in meta.variable_to_label.items():\n",
    "        var_name = str.upper(var_name)\n",
    "        if var_name[:3] in visit_prefixes:\n",
    "            var_name = var_name[3:]\n",
    "        if val_label_dict.get(var_name):\n",
    "            tmp_vl, f_list = val_label_dict[var_name]\n",
    "            if val_lbl == tmp_vl:\n",
    "                f_list.append(file)\n",
    "            else:\n",
    "                print('Mismatch: ' + var_name + ' ' + val_lbl + ' ' + tmp_vl)\n",
    "        else:\n",
    "            val_label_dict[var_name] = (val_lbl, [file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de341d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find what variables map to RACE and what files they are part of\n",
    "tmp = []\n",
    "for file, meta in files_meta.items():\n",
    "    tmp_df = pd.DataFrame([(k,v,file) for k, v in meta.variable_to_label.items()], columns=['Variable', 'Label', 'File'])\n",
    "    tmp.append(tmp_df)\n",
    "tmp_df = pd.concat(tmp, axis=0)\n",
    "tmp_df[tmp_df.Variable.str.endswith('Race') | tmp_df.Variable.str.endswith('RACE')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13aa9e8",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "    \n",
    "* Keep any eye out for dataset using: `CRTMRPH`, `WTCHG`, `$SYNACCP`, `MMMRPH` (inconsistent data definitions)\n",
    "* `kmri_sq_worms` has its own catalog file. Who knows what is going on with the `sageancillarystudy`? Both have value_labels not defined in `formats.sas7bcat`\n",
    "* `value_label` dictionaries need to be cleaned of duplicate NaNs, and the NaNs need to replaced with a Python friendly character.\n",
    "* pyreadstat isn't setting the categorical values from `value_labels`. This is probably typically fine, but for this dataset, we will want to concatenate data from different files, so standardized CategoricalDtypes are needed.\n",
    "* Columns that use SAS native data types won't expand missing value descriptions, instead raw single characters will be left in place. Out of 13K variables, over 4K fall into this category.\n",
    "* Though not shown here, early work found that variables that were all uppercase in some files were mixed case in others. SAS is case insensitive, but Python isn't. To be safe, all variable and value names from pyreadstat will be converted into upper case.\n",
    "\n",
    "**TODO**\n",
    "* Section 1.3.3 - Double check missing value marker\n",
    "* Check that variables that are reused across files have the same values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "695px",
    "left": "2640px",
    "right": "20px",
    "top": "120px",
    "width": "311px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
