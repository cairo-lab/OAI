{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9609cf0b",
   "metadata": {},
   "source": [
    "# About Converting from SAS to Dataframes\n",
    "Each dataset is examined and concatenated in a way that makes the most sense for that set. Further, column types\n",
    "are set for more efficient storage.\n",
    "\n",
    "Currently, this does not convert all dataset, but does provide tools and a template to convert any datasets not yet converted by this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f7063",
   "metadata": {},
   "source": [
    "## Merging visit datafiles\n",
    "\n",
    "145 different data files is crazy to manage for folks who are looking for correlations across datasets collected from the OAI. It has also led to a massive number of variables being defined: 11,000+. This is over 3x the actually number of unique variables measured across all visits. \n",
    "\n",
    "Given that several files are same/similar data collected across visits, this notebook defines tools to collect all that data into single files with columns to mark which visit a variable corresponds to. This greatly reduces the variable namespace. Whereas you may originally have:\n",
    "\n",
    "file 1:\n",
    "```\n",
    "ID V00FOO\n",
    "1   30.5\n",
    "2   24.7\n",
    "```\n",
    "\n",
    "file 2:\n",
    "```\n",
    "ID V01FOO\n",
    "1   31.9\n",
    "2   27.3\n",
    "```\n",
    "This merges it into a single dataframe:\n",
    "```\n",
    "ID Visit FOO\n",
    "1   V00  30.5\n",
    "2   V00  24.7\n",
    "1   V01  31.9\n",
    "2   V01  27.3\n",
    "```\n",
    "## Port data types / Set efficient storage\n",
    "\n",
    "In storage, SAS only stores values as floats or strings. This is extremely inefficient. When the pyreadstat library reads the data it has some rudimentary detection of column types. Still, most OAI columns endup as dtype object. Thus column types still need to be examined and cast to the most efficient data type.\n",
    "\n",
    "Also, SAS allows for multiple user defined data markers for any column of data. This takes two forms. The first is similar to Panda's categorical types. This can be stored efficiently in Pandas. The second allows for multiple types of missing data (where Pandas only has NA or NaN). This causes most columns to be of mixed types in Pandas (float and str).\n",
    "\n",
    "### Preserving SAS missing values in Pandas\n",
    "By allowing for user defined missing values, SAS allows you to either treat all missing values the same or leverage the fact that not all values are missing for the same reason. Neither Python Pandas (or even R's dataframes) allow this as directly. Rather than throw this information away, for any dataset that includes missing values, two dataframes will be created. The first contains all the data with NaN or NA in place of all missing values. The second will be a dataframe with NaN in place of all values, but containing the full missing value labels at the same indices they existed in the original data. This allows ignoring missing values as the default case, but when needed, an NA in the data dataframe can trigger a check for a missing value in the missing value dataframe.\n",
    "\n",
    "e.g. data\n",
    "```\n",
    "ID Visit FOO   BAR  BAZ\n",
    "1   V00  30.5   5   0.1\n",
    "2   V00  NaN    7   0.5 \n",
    "1   V01  31.9   1   0.6\n",
    "2   V01  27.3   NA  1.2\n",
    "```\n",
    "e.g. missing values/\"shadow\" dataframe\n",
    "```\n",
    "ID Visit FOO   BAR\n",
    "1   V00  30.5   5\n",
    "2   V00  NaN    7\n",
    "1   V01  31.9   1\n",
    "2   V01  27.3   NA\n",
    "```\n",
    "\n",
    "Note that columns with no missing values do not get copied to the shadow dataframe (with the exception of ID and Visit for indexing purposes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e0a32",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "Currently 5 files aren't handled yet. In each, the column naming format doesn't use visit prefixes:\n",
    "* Biospec_fnih_joco_demographics\n",
    "* biospec_fnih_joco_assays\n",
    "* kmri_poma_incoa_moaks_bicl\n",
    "* kmri_poma_tkr_chondrometrics\n",
    "* kmri_poma_tkr_moaks_bicl\n",
    "    \n",
    " A separate create_df() function needs to be made to handle these cases.\n",
    "\n",
    "\n",
    "More can be done here. For example:\n",
    "\n",
    "* Improve suggest_conversion():\n",
    "    * add the ability to detect boolean columns\n",
    "    * check for possible categoricals in numeric columns with few unique values\n",
    "    * handle columns of numeric strings (double check they have a leading 0 or other reason to be a string)\n",
    "\n",
    "* Sanity checks:\n",
    "    * in SAS string missing values are a blank, did pyreadstat capture this? string cols seem to have empty strings\n",
    "    \n",
    "* Other improvements:\n",
    "    * Add method to summarize and sanity check the missing_df shadow dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6027f5",
   "metadata": {},
   "source": [
    "# Conversion Tools\n",
    "Script to create a global dictionary of metadata needed to convert to efficient datatypes, along with functions to examine and convert the SAS data into Pandas dataframss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a91087",
   "metadata": {},
   "source": [
    "## Imports / Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fa0384",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.api.types as pdtypes\n",
    "import pickle\n",
    "import pyreadstat\n",
    "import re\n",
    "from string import digits\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "display(HTML(\"<style>.output_result { max-width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafcc3b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "data_dir = '../data/structured_data/'\n",
    "visits = {'P02':'IEI', 'P01':'SV', 'V00':'EV', 'V01':'12m', 'V02':'18m', 'V03':'24m', 'V04':'30m', 'V05':'36m',\n",
    "          'V06':'48m', 'V07':'60m', 'V08':'72m', 'V09':'84m', 'V10':'96m', 'V11':'108m', 'V99':\"Outcomes\"}\n",
    "visit_prefixes = set(visits.keys())\n",
    "\n",
    "meta_vars = [ 'column_labels',\n",
    " 'column_names',\n",
    " 'column_names_to_labels',\n",
    " 'file_encoding',\n",
    " 'file_format',\n",
    " 'file_label',\n",
    " 'missing_ranges',\n",
    " 'missing_user_values',\n",
    " 'notes',\n",
    " 'number_columns',\n",
    " 'number_rows',\n",
    " 'original_variable_types',\n",
    " 'readstat_variable_types',\n",
    " 'table_name',\n",
    " 'value_labels',\n",
    " 'variable_alignment',\n",
    " 'variable_display_width',\n",
    " 'variable_measure',\n",
    " 'variable_storage_width',\n",
    " 'variable_to_label',\n",
    " 'variable_value_labels']\n",
    "\n",
    "metadata_dict_names = ['column_names_to_labels', 'original_variable_types', 'readstat_variable_types',\n",
    "                       'value_labels', 'variable_alignment', 'variable_display_width',\n",
    "                       'variable_measure', 'variable_storage_width', 'variable_to_label', 'variable_value_labels']\n",
    "\n",
    "default_missing_value_codes = {\n",
    "    ' ': '.: Missing Form/Incomplete Workbook',\n",
    "    'A': '.A: Not Expected',\n",
    "    'B': '.B: Low/Below Range',\n",
    "    'C': '.C: Cannot Do/Attempted: unable to complete',\n",
    "    'D': '.D: Donâ€™t Know/Unknown/Uncertain',\n",
    "    'E': '.E: Non-Exposed Control',\n",
    "    'F': '.F: Not done, phone contact',\n",
    "    'G': '.G: Unreleased high value',\n",
    "    'H': '.H: High/Above range',\n",
    "    'I': '.I: Inadequate data',\n",
    "    'K': '.K: Cannot do/not attempted, unable',\n",
    "    'L': '.L: Permanently Lost',\n",
    "    'M': '.M: Missing',\n",
    "    'N': '.N: Not Required/Not edited',\n",
    "    'O': '.O: Not done, other reason',\n",
    "    'P': '.P: Prosthetic',\n",
    "    'R': '.R: Refused',\n",
    "    'S': '.S: Unreleased low value',\n",
    "    'T': '.T: Technical problems',\n",
    "    'U': '.U: Unable to examine',\n",
    "    'V': '.V: Missed visit',\n",
    "    'W': '.W: Impossible value'\n",
    "}\n",
    "default_missing_val_tokens = set(default_missing_value_codes.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dcda5b",
   "metadata": {},
   "source": [
    "## Look at the filesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7437ba3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# All SAS files\n",
    "all_files = os.listdir(data_dir)\n",
    "all_files = [x for x in all_files if '.sas7bdat' in x]\n",
    "all_files.remove('sageancillarystudy_formats.sas7bdat') ## At a binary level this seems like another CPORT file. WTF?\n",
    "all_files.sort()\n",
    "\n",
    "# How many files are there?\n",
    "print('File cnt: ' + str(len(all_files)))\n",
    "\n",
    "# How many sets?\n",
    "# Drop extensions and then drop visit suffixes\n",
    "tmp = set([f.translate(f.maketrans('', '', digits)) for f in [f.removesuffix('.sas7bdat') for f in all_files]])\n",
    "print('File set cnt: ' + str(len(tmp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e6cdb",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c06d60b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#   Given a common filename prefix, return the sorted list of sas7bdat files starting with that prefix\n",
    "# e.g. 'foo' -> ['foo01.sas7bdat', 'foo02.sas7bdat']\n",
    "def get_data_file_names(prefix):\n",
    "    file_list = [x for x in all_files if x.startswith(prefix)]\n",
    "    file_list.sort()\n",
    "    return file_list\n",
    "\n",
    "\n",
    "#   Clean visit prefixes\n",
    "# e.g. ['V01FOO', 'v02BAR'] -> ['FOO', 'BAR']\n",
    "def remove_visit_prefixes(str_list):\n",
    "    return [s[3:] if re.match(\"^[vVpP]\\d\\d\\D\\S*\", s) else s for s in str_list]\n",
    "\n",
    "\n",
    "#   Return a list of all unique prefixes\n",
    "# e.g. ['V01FOO', 'V02BAR'] -> ['V01', 'V02']\n",
    "def collect_prefixes(str_list):\n",
    "    return list({s[:3] for s in str_list if re.match(\"^[vVpP]\\d\\d\\D\\S*\", s) })\n",
    "\n",
    "#   Get value_labels from catalog file\n",
    "# The dictionaries that define user-defined types are stored in '.sas7bcat' files\n",
    "def get_value_labels(filepath):\n",
    "    _, data_catalog = pyreadstat.read_sas7bcat(filepath)\n",
    "    return data_catalog.value_labels\n",
    "\n",
    "#    Debug funct to see which files a given var name exists and the datatype in each file\n",
    "# e.g. FOO -> bar01.sas7bcat V01FOO string 3 $\n",
    "def show_sources_types(var):\n",
    "    for file, meta in files_meta.items():\n",
    "        for v in meta.column_names:\n",
    "            if v.endswith(var):\n",
    "                print(file + ' ' + v + ' ' + meta.readstat_variable_types[v] + ' ' + str(meta.variable_storage_width[v]) + ' ' + meta.variable_to_label.get(v, ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285ee5a",
   "metadata": {},
   "source": [
    "## Creating a Global Metadata Dictionary\n",
    "The `.sas7bdat` files contain the raw data, and most metadata.  `.sas7bcat` includes definitions for the user defined types.\n",
    "\n",
    "This section defines functions for handling this metadata. This primarily reads in all metadata across datasets and creates a single global dictionary of metadata. This dictionary\n",
    "can then be used to correctly set the data types for any data read in from subsequent `.sas7bdat` files.\n",
    "\n",
    "We don't care about the entire metadata set returned by pyreadstat, only `['column_names', 'readstat_variable_types', 'variable_storage_width', 'variable_to_label']`\n",
    "- See the `Exploring Available SAS Metadata` notebook for details on user-defined types and the meanings of various metadata items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ffd84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Grab the metadata across all files\n",
    "# - Roughly ~1.5 min runtime\n",
    "files_meta = {}\n",
    "for filename in all_files:\n",
    "    _, meta = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename,\n",
    "                                                         num_processes=6, metadataonly=True)\n",
    "    files_meta[filename] = meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b98bb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize names\n",
    "#  - SAS is case insensitive, to normalize names for Python, all variables from SAS are migrated to uppercase\n",
    "for file, meta in files_meta.items():\n",
    "    meta.column_names = [n.upper() for n in meta.column_names]\n",
    "    for v_name in ['readstat_variable_types', 'variable_storage_width', 'variable_to_label']:\n",
    "        var = getattr(meta, v_name)\n",
    "        setattr(meta, v_name, {k.upper(): v for k,v in var.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9d3a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make master map of original variable names to collapsed names\n",
    "# - This dict maps names like V01FOO -> FOO\n",
    "var_name_map = {}\n",
    "for meta in files_meta.values():\n",
    "    new = {n: (n[3:] if n[:3] in visit_prefixes else n) for n in meta.column_names}\n",
    "    var_name_map = {**var_name_map, **new}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6695cc61",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Building the global metadata dictionary\n",
    "# global_var_name - {storage_type, storage_width, user_defined_type}\n",
    "#\n",
    "# - The collapse of names causes 4 conflicts:\n",
    "#      name   type  width - [files]\n",
    "# COHORT\n",
    "#   V00COHORT double 8 - [Clinical_fnih.sas7bdat, enrollees.sas7bdat]\n",
    "#   COHORT string 11 - [measinventory.sas7bdat]\n",
    "# RACE\n",
    "#   RACE string 1 - [Biospec_fnih_joco_demographics.sas7bdat ]\n",
    "#   P02RACE double 8 - [Clinical_fnih.sas7bdat, enrollees.sas7bdat, measinventory.sas7bdat]\n",
    "# PTH\n",
    "#   Has value_label YNDK for allclinicalXX.sas7bdat, but no type in boneancillarystudy.sas7bdat\n",
    "# READER\n",
    "#   Has value_label '$' in most files, but no type in kmri_sq_biclXX.sas7bdat\n",
    "#\n",
    "# This code captures the common setting and leaves the outliers for custom treatment later\n",
    "\n",
    "global_meta = {}\n",
    "for meta in files_meta.values():\n",
    "    for col in meta.column_names:\n",
    "        if col not in ['RACE', 'COHORT']: # Exceptions, see above\n",
    "            descript = meta.column_names_to_labels.get(col, None)\n",
    "            storage_type = meta.readstat_variable_types[col]\n",
    "            storage_width = meta.variable_storage_width[col]\n",
    "            data_type = meta.variable_to_label.get(col, None)\n",
    "            if data_type in ['$', 'BEST', 'MMDDYY']: \n",
    "                data_type = None\n",
    "            if global_meta.get(var_name_map[col]) and col not in ['ID', 'VERSION']:\n",
    "                # storage_type\n",
    "                assert global_meta[var_name_map[col]]['storage_type'] == storage_type\n",
    "                # Set to largest storage width seen so far\n",
    "                # width\n",
    "                if global_meta[var_name_map[col]]['storage_width'] != storage_width:\n",
    "                    global_meta[var_name_map[col]]['storage_width'] = max(global_meta[var_name_map[col]]['storage_width'], storage_width)\n",
    "                # data_type\n",
    "                assert global_meta[var_name_map[col]]['data_type'] == data_type or not data_type\n",
    "            else:       \n",
    "                global_meta[var_name_map[col]] = {'storage_type': storage_type, 'storage_width': storage_width, 'data_type': data_type, 'descript': descript}\n",
    "global_meta['Visit'] = {'storage_type': None, 'storage_width': None, 'data_type': None, 'descript': 'Which visit this data was collected during'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aafacc",
   "metadata": {},
   "source": [
    "### Clean up user defined types (SAS value labels) and add to global metadata\n",
    "\n",
    "Finish the construction of the global metadata map by adding in value-labels (SAS mechanism for defining categoricals and missing value flags)\n",
    "\n",
    "The following sanity checks are applied:\n",
    "* Get rid of all NaNs and double NaNs in dictionaries\n",
    "* Confirm that if V01FOO & V02FOO collapse into FOO, then the datatypes are truly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f97114",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Grab the system-wide map of all value_labels to their user-defined type dict\n",
    "value_labels = get_value_labels(data_dir + 'formats.sas7bcat')\n",
    "\n",
    "# Create a list of value_labels associated with a double (those for data stored as strings seem fine)\n",
    "vl_doubles = []\n",
    "for name in value_labels.keys():\n",
    "    for var, meta in global_meta.items():\n",
    "        if meta['data_type'] == name and meta['storage_type'] == 'double':\n",
    "            vl_doubles.append(name)\n",
    "            break\n",
    "\n",
    "# Clean out NaNs and double NaNs            \n",
    "for name in vl_doubles:\n",
    "    value_labels[name] = {('.' if isinstance(k, float) and math.isnan(k) else k):v for k,v in value_labels[name].items()}\n",
    "    \n",
    "# Swap out data_type name for actual dictionary from value_labels\n",
    "# add in CategoricalDtype objects to be reused\n",
    "for meta in global_meta.values():\n",
    "    if meta['data_type'] and value_labels.get(meta['data_type']):\n",
    "        meta['data_type'] = value_labels[meta['data_type']]\n",
    "        meta['CategoricalDtype'] = pd.CategoricalDtype(meta['data_type'].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c13ca4",
   "metadata": {},
   "source": [
    "### Look at the scope of the name collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899d6874",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# How large is the name collapse?\n",
    "tot_col_set = set()\n",
    "for meta in files_meta.values():\n",
    "    tot_col_set.update([n.upper() for n in meta.column_names])\n",
    "print('Original number of unique variables: ' + str(len(tot_col_set)))\n",
    "print('Collapsed numer of variables: ' + str(len(set(var_name_map.values()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c36a0b8",
   "metadata": {},
   "source": [
    "## Create a single dataframe out of multiple datasets\n",
    "Create a single dataframe for all variables across a given fileset.\n",
    "\n",
    "This only sets the datatype for some columns.\n",
    "* ID - set to unsigned int\n",
    "* Visit, Version - set to Categorical\n",
    "* columns where all values are SAS user-defined - set Categorical\n",
    "\n",
    "This means that numeric columns with a mix of missing values and numbers are not automatically converted. Later functions allow you to investigate the data more closely, suggest conversions, and convert the columns as you best see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270e83a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_df(prefix):\n",
    "    # read in data from each file and append data to master dataframe\n",
    "    df_list = []\n",
    "    for filename in get_data_file_names(prefix):\n",
    "        tmp_df, _ = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename,\n",
    "                                                            num_processes=6, user_missing=True)\n",
    "       \n",
    "        # Normalize column names to uppercase (SAS is case insensitive and variable names are inconsistent across data files)\n",
    "        # DON'T drop prefixes here because a some files have data for more than one visit and common \n",
    "        # variables would collapse (and Pandas will complain about dup column names with an obscure msg)\n",
    "        tmp_df = tmp_df.rename(columns={c: c.upper() for c in tmp_df.columns})\n",
    "        print(filename + '\\tVar Cnt: ' + str(len(tmp_df.columns)))\n",
    "            \n",
    "        # What visits does this dataframe cover?\n",
    "        inc_visits = collect_prefixes(tmp_df.columns)\n",
    "        inc_visits.sort()\n",
    "        print('Visits: ' + str(inc_visits))\n",
    "        \n",
    "        # Process all variables collected in the same visit at the same time\n",
    "        for visit in inc_visits:\n",
    "            visit_vars = ['ID', 'VERSION']\n",
    "            visit_vars.extend([v for v in tmp_df.columns if v.startswith(visit)])\n",
    "            tmp2_df = tmp_df[visit_vars]\n",
    "            new_cols = {c: c.removeprefix(visit) for c in visit_vars}  # drop visit prefixes from variable names\n",
    "            tmp2_df = tmp2_df.rename(columns=new_cols)\n",
    "            # Categorical values must be set to the master set of all values for each column,\n",
    "            # otherwise categorical lists don't match when concatenating and revert to strings\n",
    "            for col in tmp2_df.columns:\n",
    "                dt = global_meta[col]['data_type']\n",
    "                if dt:\n",
    "                    if isinstance(dt, dict):\n",
    "                        # Need to swap out . for NaN\n",
    "                        if global_meta[col]['storage_type'] == 'double':\n",
    "                            tmp2_df[col].fillna('.', inplace=True)\n",
    "                        tmp2_df[col] = tmp2_df[col].apply(lambda x: dt.get(x, x))\n",
    "                        tmp2_df[col] = tmp2_df[col].astype(global_meta[col]['CategoricalDtype'])\n",
    "                    else:\n",
    "                        print('Unhandled data type: ', col, dt)\n",
    "            tmp2_df.insert(1, 'Visit', visit)  # Mark which visit these variables are associated with\n",
    "            # print(visit, tmp2_df.columns)\n",
    "            df_list.append(tmp2_df)\n",
    "\n",
    "    master_df = pd.concat(df_list, axis=0)\n",
    "    master_df['ID'] = pd.to_numeric(master_df['ID'], downcast='unsigned')\n",
    "    master_df = master_df.astype({col: 'category' for col in ['Visit', 'VERSION']})\n",
    "\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03718fe5",
   "metadata": {},
   "source": [
    "## Dataset Inspection and Type Optimization Functions\n",
    "A set of functions to examine the data being converted and help detect the columns that may need manual inspection before conversion.\n",
    "\n",
    "create_df() only sets a few column types. These function looks for columns that likely need manual conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c325f73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#     Highlights which columns change between files\n",
    "#\n",
    "# Across a series of files data00.sas7bdat-data11.sas7bdat columns may be added or\n",
    "# dropped based on the evolution of questions asked in OAI. Further, capitalization\n",
    "# may change for the column names. This function highlights those changes.\n",
    "# \n",
    "# Run before create_df() to see what is in the 'sas7bdat' files\n",
    "def column_uniformity_check(prefix):\n",
    "    tot_cnt = 0\n",
    "    col_set = {}\n",
    "    for filename in get_data_file_names(prefix):\n",
    "        tmp_df, _ = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + filename,\n",
    "                                                         catalog_file=data_dir + 'formats.sas7bcat',\n",
    "                                                         num_processes=6, user_missing=True)\n",
    "        tot_cnt += tmp_df.shape[0]\n",
    "        print('\\n' + filename + ': '+ str(tmp_df.shape))\n",
    "        \n",
    "        col_names = remove_visit_prefixes(list(tmp_df.columns))\n",
    "        if not col_set:\n",
    "            print(col_names)\n",
    "            col_set = set([c.upper() for c in col_names])\n",
    "        # display any new or missing elements \n",
    "        elif col_set ^ set(col_names):\n",
    "            # Weed out difference solely from SAS case insensitivity\n",
    "            upper_col_names = set([c.upper() for c in col_names])\n",
    "            if not col_set ^ upper_col_names:\n",
    "                print('Names only differ by case')\n",
    "            else:\n",
    "                print(list(col_set ^ set(upper_col_names)))\n",
    "                col_set = set(upper_col_names)\n",
    "\n",
    "    print('\\nTotal rows: ' + str(tot_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6aff3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#   After create_df() has been called, gather_column_data_stats() looks at the contents of each column and outputs\n",
    "# its findings in a dataframe. Indexed by the column names in the original dataset, this dataframe allows for\n",
    "# easy lookup of the column label, numeric/string/na/date value counts, min and max numeric values, the presence\n",
    "# of decimal places, and lists of unique missing values and strings present.\n",
    "#\n",
    "# Using the type data from gather_column_data_stats(), suggest_conversions() can suggest likely column types for each\n",
    "# column. It outputs a dictionary that can be pasted into a cell (modified as desired) and then serve as input to \n",
    "# convert_columns().\n",
    "\n",
    "\n",
    "\n",
    "#   Examine dataframe and return information about the data present in each column in a column indexed dataframe\n",
    "# Two dataframes are returned. The first contains data summaries for all colummns that likely still need\n",
    "# conversion. The second one containing data summaries for all columns already in categorical or uint format\n",
    "# (presumably from create_df).\n",
    "def gather_column_data_stats(df):\n",
    "    conv_list, done_list = [], []\n",
    "\n",
    "    for col in df.columns:\n",
    "        label = global_meta[col]['descript']\n",
    "        col_dtype = df[col].dtype\n",
    "        na_cnt = df[col].isna().sum()\n",
    "\n",
    "        # Type matches already converted column types\n",
    "        if col_dtype in ['category', np.uint32]:\n",
    "            done_list.append({'col': col, 'label': label, 'type': col_dtype, 'na_cnt': na_cnt})\n",
    "\n",
    "        # 100% numeric, check for type ((un)signed int, float)\n",
    "        elif col_dtype == float:\n",
    "            num_type, num_cnt, uniq_num, max_num, min_num = examine_numeric_vals(df[col])\n",
    "            add_entry(conv_list, col, label, num_type=num_type,\n",
    "                      uniq_num=uniq_num, max_num=max_num, min_num=min_num, num_cnt=num_cnt, na_cnt=na_cnt)\n",
    "\n",
    "        # object columns can be mixed types, gather stats on all type present\n",
    "        elif col_dtype == object:\n",
    "            uniq_strs, str_list, mv_list, numeric_str = None, None, None, None\n",
    "            num_type, uniq_num, max_num, min_num = None, None, None, None\n",
    "            mv_cnt, str_cnt, num_cnt, date_cnt, na_cnt = 0, 0, 0, 0, 0\n",
    "\n",
    "            \n",
    "            # look at data of each type in column\n",
    "            col_types = list(df[col].apply(type).unique())   \n",
    "            for data_type in col_types:\n",
    "                col_subset = df[col][df[col].apply(lambda x: isinstance(x, data_type))] \n",
    "                if data_type == float:\n",
    "                    num_type, num_cnt, uniq_num, max_num, min_num = examine_numeric_vals(col_subset)\n",
    "                elif data_type == str:\n",
    "                    str_cnt, uniq_strs, str_list, mv_cnt, mv_list, numeric_str = examine_str_vals(col_subset)\n",
    "                elif data_type == datetime.date:\n",
    "                    date_cnt = col_subset.shape[0]\n",
    "                else:  # Unexpected datatype\n",
    "                    print('{} contained unexpected data type: {}'.format(col, data_type))\n",
    "                    \n",
    "            # Add stats to entry for this data column\n",
    "            add_entry(conv_list, col, label, uniq_strs=uniq_strs, str_list=str_list, mv_cnt=mv_cnt, mv_list=mv_list,\n",
    "                      numeric_str=numeric_str, num_type=num_type, uniq_num=uniq_num, max_num=max_num, min_num=min_num, \n",
    "                      str_cnt=str_cnt, num_cnt=num_cnt, date_cnt=date_cnt, na_cnt=na_cnt)\n",
    "        else:\n",
    "            print('{} contained unexpected data type: {}'.format(col, data_type))\n",
    "        \n",
    "    return pd.DataFrame(conv_list).set_index('col'), pd.DataFrame(done_list).set_index('col')\n",
    "\n",
    "\n",
    "#   Using the output of gather_column_data_stats() display a dictionary suggesting what Pandas types each\n",
    "# column should be converted to.\n",
    "def suggest_conversions(df):\n",
    "    print('targets = {')\n",
    "    # Dates\n",
    "    count_cols = ['str_cnt', 'num_cnt', 'date_cnt', 'na_cnt']\n",
    "    subset = df[count_cols].apply(lambda x: x > 0)\n",
    "    dates = df[~subset.str_cnt & ~subset.num_cnt & subset.date_cnt].index.to_list()\n",
    "    dates.extend(df[subset.str_cnt & ~subset.num_cnt & subset.date_cnt & (df.uniq_strs == 0)].index.to_list())\n",
    "    if dates:\n",
    "        print('# Columns with only dates, missing, and NA values')\n",
    "        print(\"'date': {},\\n\".format(dates))\n",
    "    \n",
    "    # Numeric\n",
    "    numeric = df[subset.num_cnt & ~subset.date_cnt & (df.uniq_strs == 0)]\n",
    "    unsigned = numeric[numeric.num_type == 'unsigned'].index.to_list()\n",
    "    if unsigned:\n",
    "        print('# Columns with only unsigned ints, missing, and NA values')\n",
    "        print(\"'unsigned': {},\\n\".format(unsigned))\n",
    "\n",
    "    signed = numeric[numeric.num_type == 'signed'].index.to_list()\n",
    "    if signed:\n",
    "        print('# Columns with only signed ints, missing, and NA values')\n",
    "        print(\"'signed': {},\\n\".format(signed))\n",
    "\n",
    "    floats = numeric[numeric.num_type == 'float'].index.to_list()\n",
    "    if floats:\n",
    "        print('# Columns with only floats, missing, and NA values')\n",
    "        print(\"'float': {},\\n\".format(floats))\n",
    "\n",
    "    # Strings\n",
    "    strings = df[subset.str_cnt & ~subset.num_cnt & ~subset.date_cnt].index.to_list()\n",
    "    if strings:\n",
    "        print('# Columns with only strings, missing, and NA values')\n",
    "        print(\"'cat': {},\\n\".format(strings))\n",
    "    print('}\\n')\n",
    "    \n",
    "    print('\\nHandled columns: {}'.format(len(dates) + len(unsigned) + len(signed) + len(floats) + len(strings)))\n",
    "    \n",
    "    missing_cols = set(df.index.to_list()) - set(dates+unsigned+signed+floats+strings)\n",
    "    if missing_cols:\n",
    "        print('Unhandled columns: {}'.format(missing_cols))\n",
    "        \n",
    "\n",
    "#   Given a dictionary mapping types to lists of columns to convert to that type, along with the type information\n",
    "# information dataframe, and the data itself, return a dataframe with the corresponding columns converted as well\n",
    "# as a matching \"shadow\" dataframe of missing values.\n",
    "#\n",
    "# If no missing values are present anywhere in the dataset, an empty dataframe is returned\n",
    "def convert_columns(targets, data_stats_df, df):\n",
    "    # create the shadow datframe for missing values\n",
    "    all_cols = [col for col_list in targets.values() for col in col_list]\n",
    "    cols_w_missing = [col for col in all_cols if data_stats_df.loc[col, 'missing_val_cnt'] > 0]\n",
    "    missing_df = df[cols_w_missing].applymap(lambda x: x if isinstance(x, str) else np.NaN)\n",
    "    missing_df = missing_df.applymap(lambda x: default_missing_value_codes.get(x, x))\n",
    "    missing_df = missing_df.astype('category')\n",
    "    if not missing_df.empty:\n",
    "        missing_df['ID'] = df['ID']\n",
    "        missing_df['Visit'] = df['Visit']\n",
    "        missing_df = missing_df.set_index(['ID', 'Visit'])\n",
    "        \n",
    "    for col_type, cols_to_conv in targets.items():\n",
    "        na = np.NaN\n",
    "        if col_type in ['unsigned', 'signed']:\n",
    "            na = pd.NA\n",
    "        \n",
    "        # Now that missing values are copied to a shadow dataframe, remove them from the dataframe\n",
    "        cols_w_missing = [col for col in cols_to_conv if data_stats_df.loc[col, 'missing_val_cnt'] > 0]\n",
    "        replace_dict = {col: {val: na for val in data_stats_df.loc[col, 'missing_val_list']} for col in cols_w_missing}\n",
    "        df[cols_w_missing] = df[cols_w_missing].replace(replace_dict)   \n",
    "        \n",
    "        if col_type in ['signed', 'unsigned']:\n",
    "            cols_w_nas = [col for col in cols_to_conv if data_stats_df.loc[col, 'na_cnt'] > 0]\n",
    "            df[cols_w_nas] = df[cols_w_nas].fillna(pd.NA) # Manual conversions needed due to presence of NaNs\n",
    "            cols_w_nas = list(set(cols_w_nas + cols_w_missing))\n",
    "            df[cols_w_nas] = df[cols_w_nas].astype('Int32')  # Int32 allows for pd.NA values\n",
    "            \n",
    "            df[cols_to_conv] = df[cols_to_conv].apply(pd.to_numeric, downcast=col_type)\n",
    "\n",
    "        elif col_type == 'float':\n",
    "            df[cols_to_conv] = df[cols_to_conv].apply(pd.to_numeric, downcast='float')\n",
    "        elif col_type == 'cat':\n",
    "            df[cols_to_conv] = df[cols_to_conv].astype('category')\n",
    "        elif col_type == 'date':\n",
    "            df[cols_to_conv] = df[cols_to_conv].astype('datetime64[ns]')\n",
    "   \n",
    "    return df.set_index(['ID', 'Visit']), missing_df\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "#   Check for numeric type ((un)signed int, float. NaN), min, max, unique cnt \n",
    "def examine_numeric_vals(col):\n",
    "    num_type = 'float'\n",
    "    min_val, max_val = col.min(), col.max()\n",
    "    unique_cnt = len(col.unique())\n",
    "\n",
    "    # Does it really need to be a float?\n",
    "    if col[~col.isna()].apply(float.is_integer).all():  # ignoring NaNs, are the rest integers?\n",
    "        num_type = 'unsigned'\n",
    "        if min_val < 0:\n",
    "            num_type = 'signed'\n",
    "\n",
    "    num_cnt = col.shape[0] - col.isna().sum()\n",
    "    # Are they all NA?\n",
    "    if num_cnt == 0:\n",
    "        num_type = 'na'\n",
    "            \n",
    "    return num_type, num_cnt, unique_cnt, max_val, min_val\n",
    "\n",
    "\n",
    "#   Get a list of unique strs, and whether strings are numbers\n",
    "def examine_str_vals(col):\n",
    "    missing_vals = set([k for k in default_missing_value_codes.keys()])\n",
    "    uniques = set(col.unique()) - missing_vals\n",
    "    missing_vals = missing_vals & set(col.unique())\n",
    "    unique_cnt = len(uniques)\n",
    "    \n",
    "    # Are they all strings written as strings?\n",
    "    numeric_str = False\n",
    "    if not pd.to_numeric(col, errors='coerce').isna().any():\n",
    "        numeric_str = True\n",
    "    return col.shape[0], len(uniques), uniques, len(missing_vals), missing_vals, numeric_str\n",
    "\n",
    "\n",
    "#    Add column data to list\n",
    "# - convenience function to reduce argument count\n",
    "def add_entry(conv_list, col_name, label, uniq_strs=0, str_list=None, mv_cnt=0, mv_list=None, numeric_str=None,\n",
    "              num_type=None, uniq_num=None, max_num=None, min_num=None, str_cnt=0, num_cnt=0, date_cnt=0, na_cnt=0):\n",
    "    conv_list.append({'col': col_name, 'label': label, 'uniq_strs': uniq_strs, 'str_list': str_list, \n",
    "                      'missing_val_cnt': mv_cnt, 'missing_val_list': mv_list, 'numeric_str': numeric_str,\n",
    "                      'num_type': num_type, 'uniq_num': uniq_num, 'max_num': max_num, 'min_num': min_num, \n",
    "                      'str_cnt': str_cnt, 'num_cnt': num_cnt, 'date_cnt': date_cnt, 'na_cnt': na_cnt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4cddf1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#         Column data stats summary functions - called after gather_column_data_stats()\n",
    "\n",
    "#   Print a dataframe wide summary of the datatypes found in the analysis\n",
    "# arguments - data dataframe, data summary dataframe\n",
    "def data_stats_summary(df, data_stats_df):\n",
    "    print('Already defined cols: {} \\tCols to convert: {}\\t Total col cnt: {}'.format(df.shape[1] - data_stats_df.shape[0], data_stats_df.shape[0], df.shape[1]))\n",
    "    print('\\nColumn types to convert:\\n{}'.format(column_types_present(data_stats_df)))\n",
    "    print('\\nNumeric types of columns:\\n{}'.format(data_stats_df['num_type'].value_counts()))\n",
    "    print('\\nLargest number of unique strings: {}'.format(data_stats_df['uniq_strs'].max()))\n",
    "    #print('\\nHistogram of different NA count sizes:\\n{}'.format(data_stats_df['na_cnt'].value_counts()))\n",
    "\n",
    "    \n",
    "#    Print a table of the combinations of data types found across columns in the analysis\n",
    "# arguments - data summary dataframe\n",
    "def column_types_present(df):\n",
    "    count_cols = ['str_cnt', 'num_cnt', 'date_cnt', 'na_cnt']\n",
    "    subset = df[count_cols]\n",
    "    subset = subset.apply(lambda x: x > 0)\n",
    "    return subset.groupby(count_cols).size().reset_index().rename(columns={0:'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496200f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Inspect values and types\n",
    "                \n",
    "#   Show string columns data to look for patterns\n",
    "def show_string_col_stats(stats_df):\n",
    "    count_cols = ['str_cnt', 'num_cnt', 'date_cnt', 'na_cnt']\n",
    "    subset = stats_df[count_cols].apply(lambda x: x > 0)\n",
    "    return stats_df[subset.str_cnt & ~subset.num_cnt & ~subset.date_cnt & subset.na_cnt]                \n",
    "\n",
    "\n",
    "#    Check the converted dataframe for wrong and suspcious things\n",
    "#  List which columns aren't categoricals though create_df should have made them so\n",
    "#  List which columns have NA/NaN values though they weren't expected to\n",
    "def sanity_check(df):\n",
    "    # Confirm all categorical columns expected to be categorical are\n",
    "    for col in df:\n",
    "        if col not in ['Visit', 'VERSION'] and  global_meta[col]['data_type']:\n",
    "            if not pdtypes.is_categorical_dtype(df[col]):\n",
    "                print('Failure to make column categorical: ' + col)\n",
    "            if df[col].isna().all():\n",
    "                print('All NaN in categorical col: ' + col)\n",
    "    if df.select_dtypes(include='object').columns.to_list():\n",
    "        print('Columns still object type: ', df.select_dtypes(include='object').columns.to_list())         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0236aa",
   "metadata": {},
   "source": [
    "# Dataset Conversions\n",
    "Processed in alphabetical order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b07048",
   "metadata": {},
   "source": [
    "## Biospec_fnih_joco_demographics\n",
    "TODO: Not handled yet as column naming format doesn't use visit prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901bce3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'Biospec_fnih_joco_demographics'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0064eadc",
   "metadata": {},
   "source": [
    "## Clinical_fnih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce9520e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'Clinical_fnih'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93faba09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71356c12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad27e822",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e5cab8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443355cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['AGE'],\n",
    "\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['BMI', 'XRJSM', 'XRJSL', 'MCMJSW', 'WOMKP', 'WOMADL'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f53cbe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53b3e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de5ea7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a341567b",
   "metadata": {},
   "source": [
    "## acceldatabyday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27f4ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'acceldatabyday'\n",
    "column_uniformity_check(prefix)  # Becasue there is more than one dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12bf95a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520faa2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9934aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107f957",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0137b19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['PASTUDYDAY', 'VDAYSEQUENCE', 'PAMONTH', 'DAYMODMINT', 'DAYMODMINF', 'DAYMODMINS', 'DAYVIGMINT', 'DAYVIGMINF', 'DAYVIGMINS', 'DAYMVMINT', 'DAYMVMINF', 'DAYMVMINS', 'DAYCNT', 'DAYLTMINT', 'DAYLTMINF', 'DAYLTMINS', 'DAYMVBOUTMINT', 'DAYMVBOUTMINF', 'DAYMVBOUTMINS', 'DAYVBOUTMINT', 'DAYVBOUTMINF', 'DAYVBOUTMINS'],\n",
    "\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['WEARHR'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['PAWEEKDAY'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535805cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f626d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d4a3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea2075c",
   "metadata": {},
   "source": [
    "## acceldatabymin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e96a83",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'acceldatabymin'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6573f955",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f60ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da548db",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24daa37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2056d26a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['PASTUDYDAY', 'MINSEQUENCE', 'SUSPECTMINUTE', 'MINCNT', 'PAMONTH'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['PAWEEKDAY'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea778c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_df['SUSPECTMINUTE'] = new_df['SUSPECTMINUTE'].astype('bool')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ccdb73",
   "metadata": {},
   "source": [
    "TODO: SUSPECTMINUTE should be a bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d19d637",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "\n",
    "if not missing_df.empty:\n",
    "    print('Missing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb109bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('\\nShadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3cbfa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2024661",
   "metadata": {},
   "source": [
    "## accelerometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca2b05",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'accelerometry'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd17b61",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c86cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0fcc1b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5fe451",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e2f2a4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['AMPA1', 'ANVDAYS'],\n",
    "\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['AAVMNT', 'AAMVBMF', 'AAMVBMT', 'AAMVMNS', 'AAVBMS', 'AAMVBMS', 'AAMVMNT', 'AACSM03', 'AAMVMNF', 'AAVMNF', 'AACNT', 'AALTMNF', 'AAMDMNF', 'AAVBMT', 'AALTMNT', 'AAMDMNT', 'AAVBMF', 'AALTMNS', 'AAMDMNS', 'AAVMNS'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['APASTAT'],\n",
    "\n",
    "}\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e863aec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef8029",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabed5e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca2953",
   "metadata": {},
   "source": [
    "## allclinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79902f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'allclinical'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b4ed0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8f860",
   "metadata": {},
   "source": [
    "Note the compression from 7016 variables to 1851."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f20c31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d486ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507766f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535fa9a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only dates, missing, and NA values\n",
    "'date': ['SVDATE', 'DATE', 'EVDATE', 'PSDATE', 'SSDATE', 'FVDATE', 'ISEXMDT'],\n",
    "\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['KPNR12M', 'KPNL12M', 'TMJE30D', 'TMJE30A', 'TMJF30D', 'TMJF30A', 'BPTOT', 'BPDAYCV', 'BPBEDCV', 'KPACDCV', 'INJR1', 'INJR2', 'INJR3', 'KRSRA', 'ARTR1', 'ARTR2', 'ARTR3', 'MENR1', 'MENR2', 'MENR3', 'LRR1', 'LRR2', 'OTSR1', 'OTSR2', 'OTSR3', 'INJL1', 'INJL2', 'INJL3', 'KRSLA', 'ARTL1', 'ARTL2', 'ARTL3', 'MENL1', 'MENL2', 'MENL3', 'LRL1', 'OTSL1', 'OTSL2', 'OTSL3', 'OV1AGE', 'OV2AGE', 'HYSAGE', 'BLDHRS1', 'BLDHRS2', 'BLSURD1', 'BLSURD2', 'HOURSP1', 'HOURSP2', 'PDATE1', 'PDATE2', 'PLAQHR1', 'PLAQHR2', 'SEAQHR1', 'SEAQHR2', 'UCDATE1', 'UCDATE2', 'URINHR1', 'URINHR2', 'URSURD1', 'URSURD2', 'WOMSTFR', 'WOMSTFL', 'HIPFXAG', 'SPNFXAG', 'SMKAGE', 'SMKAVE', 'SMKAMT', 'SMKSTOP', 'PIPEAGE', 'PIPEAMT', 'PIPSTOP', 'BISPYRS', 'RX30NUM', 'COMORB', 'SMKPKYR', 'PSMKYR', 'CESD', 'NWARNS', 'NNOSERV', 'NSKIP', 'NERRORS', 'BPSYS', 'BPDIAS', 'RPAVG', 'STEPST1', 'STEPST2', 'HRB4WLK', 'NUMSTOP', 'HR400WK', 'LLWGT', 'RLWGT', '400MTR', 'AGE', 'HOURWK', 'MISSWK', 'PASE', 'WEEKWK', 'WKHR7CV', 'BLUPMN1', 'BLUPMN2', 'PRRDDYS', 'URUPMN2', 'VISDYS', 'AMPA1', 'ANVDAYS', 'SF12BP', 'SF12PF', 'SF12VT', 'SF12SF', 'WTLSYR', 'AC1AR1', 'AC2AR1', 'AC3AR1', 'AC1AR2', 'AC2AR2', 'AC3AR2', 'AC1AR3', 'AC2AR3', 'AC3AR3', 'AC1AR4', 'AC2AR4', 'AC3AR4'],\n",
    "\n",
    "# Columns with only signed ints, missing, and NA values\n",
    "'signed': ['RKFHDEG', 'LKFHDEG', 'RKALNMT', 'LKALNMT', 'DFBCOLL', 'DFUCOLL', 'URUPMN1'],\n",
    "\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['HEIGHT', 'WEIGHT', 'BMI', 'HRSUC1', 'HRSUC2', 'HSPSS', 'HSMSS', 'WOMKPR', 'KOOSKPR', 'KOOSYMR', 'WOMADLR', 'WOMKPL', 'KOOSKPL', 'KOOSYML', 'WOMADLL', 'KOOSFSR', 'KOOSQOL', 'WOMTSL', 'WOMTSR', 'HT25MM', 'WT25KG', 'WTMAXKG', 'WTMINKG', 'DTDFIB', 'SUPVITD', 'FIBVGFR', 'SUPB12', 'DTCAFFN', 'SRVFAT', 'DTAIU', 'DTCHOL', 'PCTCOL1', 'DTPHOS', 'DTVITC', 'DTB1', 'PCTXLS', 'SUPB2', 'PCTCOL9', 'DTVITK', 'DTRET', 'SUPVITE', 'SUPNIAC', 'DTANZN', 'DTLUT', 'BAPFAT', 'PCTCARB', 'PCTSWT', 'DTACAR', 'SUPCA', 'SRVGRN', 'SRVFRT', 'SUPFOL', 'DTBCAR', 'DTPROT', 'DTPOTA', 'DTSFAT', 'SUPVITC', 'DTOLEC', 'SUPBCAR', 'DTKCAL', 'BAPPROT', 'BAPCARB', 'SUPVITA', 'SUPB6', 'NFDSDAY', 'DTNIAC', 'FIBBEAN', 'DTNA', 'DTARE', 'DTLYC', 'DTFAT', 'PCTSMAL', 'SUPFE', 'SUPCU', 'DTB12', 'DTGEN', 'DTMETH', 'SUPZINC', 'SRVVEG', 'DTCALC', 'SUPMG', 'DTDAID', 'SRVMEAT', 'DTFE', 'FIBGRN', 'DTCYST', 'DTSF', 'PCTPROT', 'SRVDRY', 'DTB6', 'SUPB1', 'SUPSE', 'DTMG', 'PCTFAT', 'DTVITD', 'DTPROA', 'DTCARB', 'PCTALCH', 'DTFOL', 'DTLIN', 'PCTLARG', 'DTVITE', 'DTCRYP', 'PCTMEDS', 'DTRIBO', 'DTZINC', 'CSTIME1', 'CSTIME2', 'RLLGTH', 'RLBACK', 'RLARM', 'RLHORIZ', 'RLVERT', 'LLLGTH', 'LLBACK', 'LLARM', 'LLHORIZ', 'LLVERT', 'TIMET1', 'TIMET2', 'ABCIRC', 'CSPACE', '20MPACE', 'RFTLPL', 'RFTHPL', 'RFTLRL', 'RFTHRL', 'RETLPL', 'RETHPL', 'RETLRL', 'RETHRL', 'LFTLPL', 'LFTHPL', 'LFTLRL', 'LFTHRL', 'LETLPL', 'LETHPL', 'LETLRL', 'LETHRL', '400MTIM', 'RFSFR', 'LESFR', 'LFSFP', 'RESFP', 'RESFR', 'LFSFR', 'RFSFP', 'LESFP', 'ICPTSKL', 'ICPTSKR', 'IPSKL', 'CPSKR', 'IPSKR', 'CPSKL', 'LLDILSM', 'LLDIFST', 'LLDILST', 'LLDIFSS', 'LLDILSI', 'LLDIFSP', 'AAVMNT', 'AAMVBMF', 'AAMVBMT', 'AAMVMNS', 'AAVBMS', 'AAMVBMS', 'AAMVMNT', 'AACSM03', 'AAMVMNF', 'AAVMNF', 'AACNT', 'AALTMNF', 'AAMDMNF', 'AAVBMT', 'AALTMNT', 'AAMDMNT', 'AAVBMF', 'AALTMNS', 'AAMDMNS', 'AAVMNS', 'IPSHL', 'IPSHR', 'ICPTSHR', 'CPSHL', 'ICPTSHL', 'CPSHR', 'SF12RP', 'SF12RE', 'SF12GH', 'SF12MH'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['LRR3', 'LRL2', 'LRL3', 'STFID2', 'STFID1', 'HESTFID', 'SVXRRID', 'BPSTFID', 'RPSTFID', 'ACSTFID', 'SCSTFID', 'RCSTFID', 'W2STFID', 'W4STFID', 'K1STFID', 'ISSTFID', 'WPSTFID', 'K5STFID', 'KPSTFID', 'APASTAT', 'HVSTFID', 'WLC1IL'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b037fb85",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba425f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e675e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82929a10",
   "metadata": {},
   "source": [
    "## biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febcba4b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'biomarkers'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead9d8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da41d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb35d40",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e22876",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ba942",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['BLDHRS1', 'BLDHRS2', 'BLSURD1', 'BLSURD2', 'HOURSP1', 'HOURSP2', 'PDATE1', 'PDATE2', 'PLAQHR1', 'PLAQHR2', 'SEAQHR1', 'SEAQHR2', 'UCDATE1', 'UCDATE2', 'URINHR1', 'URINHR2', 'URSURD1', 'URSURD2', 'BLUPMN1', 'BLUPMN2', 'PRRDDYS', 'URUPMN2'],\n",
    "\n",
    "# Columns with only signed ints, missing, and NA values\n",
    "'signed': ['DFBCOLL', 'DFUCOLL', 'URUPMN1'],\n",
    "\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['HRSUC1', 'HRSUC2'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfecc6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3dd40",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4bda20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14d0235",
   "metadata": {},
   "source": [
    "## biospec_fnih_joco_assays\n",
    "TODO: Not handled yet as column naming format doesn't use visit prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0427f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'biospec_fnih_joco_assays'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae1a943",
   "metadata": {},
   "source": [
    "## biospec_fnih_labcorp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fc5ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'biospec_fnih_labcorp'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a751f8d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e7e263",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff9876c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9e9cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f95dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['SERUM_C2C_NUM', 'SERUM_CPII_NUM', 'SERUM_PIIANP_NUM', 'SERUM_CS846_NUM', 'SERUM_COMP_NUM', 'SERUM_HA_NUM', 'SERUM_NTXI_NUM', 'URINE_C2C_NUM', 'URINE_NTXI_NUM', 'SERUM_C2C_ALTNUM', 'SERUM_CPII_ALTNUM', 'SERUM_CS846_ALTNUM', 'SERUM_COMP_ALTNUM', 'SERUM_HA_ALTNUM', 'SERUM_NTXI_ALTNUM', 'SERUM_PIIANP_ALTNUM', 'URINE_C2C_ALTNUM', 'URINE_NTXI_ALTNUM', 'SERUM_C1_2C_LOWLIM', 'SERUM_C2C_LOWLIM', 'SERUM_COLL2_1_NO2_LOWLIM', 'SERUM_CPII_LOWLIM', 'SERUM_CS846_LOWLIM', 'SERUM_CTXI_LOWLIM', 'SERUM_COMP_LOWLIM', 'SERUM_HA_LOWLIM', 'SERUM_MMP_3_LOWLIM', 'SERUM_NTXI_LOWLIM', 'SERUM_PIIANP_LOWLIM', 'URINE_CTXII_LOWLIM', 'URINE_C1_2C_LOWLIM', 'URINE_C2C_LOWLIM', 'URINE_NTXI_LOWLIM', 'URINE_ALPHA_LOWLIM', 'URINE_BETA_LOWLIM', 'URINE_COL21N2_LOWLIM'],\n",
    "\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['SERUM_C1_2C_NUM', 'SERUM_COLL2_1_NO2_NUM', 'SERUM_CTXI_NUM', 'SERUM_MMP_3_NUM', 'URINE_CTXII_NUM', 'URINE_C1_2C_NUM', 'URINE_CREATININE_NUM', 'URINE_ALPHA_NUM', 'URINE_BETA_NUM', 'URINE_COL21N2_NUM', 'URINE_CTXII_NUMCA', 'URINE_C1_2C_NUMCA', 'URINE_C2C_NUMCA', 'URINE_NTXI_NUMCA', 'URINE_ALPHA_NUMCA', 'URINE_BETA_NUMCA', 'URINE_COL21N2_NUMCA', 'SERUM_C1_2C_ALTNUM', 'SERUM_COLL2_1_NO2_ALTNUM', 'SERUM_CTXI_ALTNUM', 'SERUM_MMP_3_ALTNUM', 'URINE_CTXII_ALTNUM', 'URINE_C1_2C_ALTNUM', 'URINE_ALPHA_ALTNUM', 'URINE_BETA_ALTNUM', 'URINE_COL21N2_ALTNUM', 'URINE_CTXII_ALTNUMCA', 'URINE_C1_2C_ALTNUMCA', 'URINE_C2C_ALTNUMCA', 'URINE_NTXI_ALTNUMCA', 'URINE_ALPHA_ALTNUMCA', 'URINE_BETA_ALTNUMCA', 'URINE_COL21N2_ALTNUMCA', 'URINE_COL21N2SD', 'URINE_COL21N2CV'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['SERUM_C1_2C_LC', 'SERUM_C2C_LC', 'SERUM_COLL2_1_NO2_LC', 'SERUM_CPII_LC', 'SERUM_CS846_LC', 'SERUM_CTXI_LC', 'SERUM_COMP_LC', 'SERUM_HA_LC', 'SERUM_MMP_3_LC', 'SERUM_NTXI_LC', 'SERUM_PIIANP_LC', 'URINE_CTXII_LC', 'URINE_C1_2C_LC', 'URINE_C2C_LC', 'URINE_CREATININE_LC', 'URINE_NTXI_LC', 'URINE_ALPHA_LC', 'URINE_BETA_LC', 'SERUM_C1_2C_COMMENT', 'SERUM_C2C_COMMENT', 'SERUM_COLL2_1_NO2_COMMENT', 'SERUM_CPII_COMMENT', 'SERUM_CS846_COMMENT', 'SERUM_CTXI_COMMENT', 'SERUM_COMP_COMMENT', 'SERUM_HA_COMMENT', 'SERUM_MMP_3_COMMENT', 'SERUM_NTXI_COMMENT', 'SERUM_PIIANP_COMMENT', 'URINE_CTXII_COMMENT', 'URINE_C1_2C_COMMENT', 'URINE_C2C_COMMENT', 'URINE_CREATININE_COMMENT', 'URINE_NTXI_COMMENT', 'URINE_ALPHA_COMMENT', 'URINE_BETA_COMMENT', 'SERUM_C1_2C_HQC', 'SERUM_C2C_HQC', 'SERUM_COLL2_1_NO2_HQC', 'SERUM_CPII_HQC', 'SERUM_CS846_HQC', 'SERUM_CTXI_HQC', 'SERUM_COMP_HQC', 'SERUM_HA_HQC', 'SERUM_MMP_3_HQC', 'SERUM_NTXI_HQC', 'SERUM_PIIANP_HQC', 'URINE_CTXII_HQC', 'URINE_CREATININE_HQC', 'URINE_NTXI_HQC', 'URINE_ALPHA_HQC', 'URINE_BETA_HQC', 'SERUM_C1_2C_LQC', 'SERUM_C2C_LQC', 'SERUM_COLL2_1_NO2_LQC', 'SERUM_CPII_LQC', 'SERUM_CS846_LQC', 'SERUM_CTXI_LQC', 'SERUM_COMP_LQC', 'SERUM_HA_LQC', 'SERUM_MMP_3_LQC', 'SERUM_NTXI_LQC', 'SERUM_PIIANP_LQC', 'URINE_CTXII_LQC', 'URINE_C1__2C_LQC', 'URINE_C2C_LQC', 'URINE_CREATININE_LQC', 'URINE_NTXI_LQC', 'URINE_ALPHA_LQC', 'URINE_BETA_LQC', 'SERUM_C1_2C_MQC', 'SERUM_C2C_MQC', 'SERUM_CPII_MQC', 'SERUM_CS846_MQC', 'SERUM_MMP_3_MQC', 'URINE_C1__2C_MQC', 'URINE_C2C_MQC', 'SERUM_C1_2C_KIT_LOT_NUM', 'SERUM_C2C_KIT_LOT_NUM', 'SERUM_COLL2_1_NO2_KIT_LOT_NUM', 'SERUM_CPII_KIT_LOT_NUM', 'SERUM_CS846_KIT_LOT_NUM', 'SERUM_CTXI_KIT_LOT_NUM', 'SERUM_COMP_KIT_LOT_NUM', 'SERUM_HA_KIT_LOT_NUM', 'SERUM_MMP_3_KIT_LOT_NUM', 'SERUM_NTXI_KIT_LOT_NUM', 'SERUM_PIIANP_KIT_LOT_NUM', 'URINE_CTXII_KIT_LOT_NUM', 'URINE_C1__2C_KIT_LOT_NUM', 'URINE_C2C_KIT_LOT_NUM', 'URINE_CREATININE_KIT_LOT_NUM', 'URINE_NTXI_KIT_LOT_NUM', 'URINE_ALPHA_KIT_LOT_NUM', 'URINE_BETA_KIT_LOT_NUM', 'SERUM_C1_2C_PLATE_ID', 'SERUM_C2C_PLATE_ID', 'SERUM_COLL2_1_NO2_PLATE_ID', 'SERUM_CPII_PLATE_ID', 'SERUM_CS846_PLATE_ID', 'SERUM_CTXI_PLATE_ID', 'SERUM_COMP_PLATE_ID', 'SERUM_HA_PLATE_ID', 'SERUM_MMP_3_PLATE_ID', 'SERUM_NTXI_PLATE_ID', 'SERUM_PIIANP_PLATE_ID', 'URINE_CTXII_PLATE_ID', 'URINE_C1__2C_PLATE_ID', 'URINE_C2C_PLATE_ID', 'URINE_CREATININE_PLATE_ID', 'URINE_NTXI_PLATE_ID', 'URINE_ALPHA_PLATE_ID', 'URINE_BETA_PLATE_ID'],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a8d55",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b4c62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d6222",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f54243",
   "metadata": {},
   "source": [
    "## boneancillarystudy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807afdfc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'boneancillarystudy'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb6c76",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dbd202",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a86c49",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdcfafb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1151155c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only dates, missing, and NA values\n",
    "'date': ['KNEEDXADT', 'TRABMRSEQDT', 'HIPDXADT', 'PDATE'],\n",
    "\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['KNEEDXASFWARE', 'VITD'],\n",
    "\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['MEDIALBMD', 'LATERALBMD', 'BMDRATIO', 'BVF', 'TRN', 'TRSP', 'TRTH', 'NECKBMD'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb8a09a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0e13e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9391b810",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d15d5c9",
   "metadata": {},
   "source": [
    "## enrollees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf02833",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'enrollees'\n",
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print(tmp_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7334c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Are all variables associated with the same release VERSION?\n",
    "tmp_df['VERSION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ef7600",
   "metadata": {},
   "source": [
    "From reading about the data, the enrollees data is best stored as two separate dataframes:\n",
    "* One has basic data about the enrollees collected at either the IEI or EV. \n",
    "* The second tracks participation in different image groups by visit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a0ecf",
   "metadata": {},
   "source": [
    "### Enrollee Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b56f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "enrollee_df = tmp_df[tmp_df['Visit'] == 'P02'].copy()\n",
    "enrollee_df.dropna(how='all', axis='columns', inplace=True)  # Drop all columns for data that wasn't collected during visit P02\n",
    "enrollee_df.drop('Visit', axis='columns', inplace=True)  # this information is independent of the visit\n",
    "\n",
    "enrollee_df = enrollee_df.join(tmp_df[tmp_df['Visit'] == 'V00'][['ID', 'CHRTHLF', 'COHORT', 'SITE']].set_index('ID'), on='ID')\n",
    "enrollee_df = enrollee_df.join(tmp_df[tmp_df['Visit'] == 'V01'][['ID', 'HADINTV']].set_index('ID'), on='ID')\n",
    "enrollee_df = enrollee_df.astype({'SITE': 'category'})\n",
    "enrollee_df.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677c160f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(enrollee_df)\n",
    "print()\n",
    "print(enrollee_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f8d01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(enrollee_df, open('pkl/enrollees_values.pkl', 'wb'))\n",
    "enrollee_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd85e8",
   "metadata": {},
   "source": [
    "### Image Group Participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4448c58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for v in ['V00', 'V01', 'V02', 'V03', 'V04', 'V05', 'V06', 'V08', 'V10']:\n",
    "    image_groups_df = tmp_df[tmp_df['Visit'] == v].copy()\n",
    "    image_groups_df.dropna(how='all', axis='columns', inplace=True)\n",
    "    if v == 'V00':\n",
    "        image_groups_df.drop(['CHRTHLF', 'COHORT', 'SITE'], axis='columns', inplace=True)\n",
    "    if v == 'V01':\n",
    "        image_groups_df.drop(['HADINTV'], axis='columns', inplace=True)\n",
    "    df_list.append(image_groups_df)\n",
    "image_groups_df = pd.concat(df_list, axis=0)\n",
    "image_groups_df = image_groups_df.set_index(['ID', 'Visit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caefae1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(image_groups_df)\n",
    "print()\n",
    "print(image_groups_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07172f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(image_groups_df, open('pkl/image_groups_values.pkl', 'wb'))\n",
    "df_list = None\n",
    "image_groups_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05696d0",
   "metadata": {},
   "source": [
    "## flxr_kneealign_cooke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc89a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'flxr_kneealign_cooke'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c38f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293f9bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819a43c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084c3b84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6edfd1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['HKANGLE'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BARCDDC'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563dca29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f269f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7647c91",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d292d9",
   "metadata": {},
   "source": [
    "## flxr_kneealign_duryea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c64e62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'flxr_kneealign_duryea'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674bd85f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af289f09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f071f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf18fe45",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79506c97",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['HKANGJD', 'FEMLEN', 'TIBLEN', 'APPLL'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BRCDHJD'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24c7c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef72ee8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8a2c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b18628",
   "metadata": {},
   "source": [
    "## kmri_fnih_boneshape_imorphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730a53f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kmri_fnih_boneshape_imorphics'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ed7ec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f14e60",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1849589",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c3b3ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d838a15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['MF_TAB', 'LF_TAB', 'MT_TAB', 'LT_TAB', 'MP_TAB', 'LP_TAB', 'NOTCH', 'TRFLAT', 'TRFMED', 'NFEMUROAVECTOR', 'NTIBIAOAVECTOR', 'NPATELLAOAVECTOR'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BARCDIM'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1aac53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a871e4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e815f1c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226105d0",
   "metadata": {},
   "source": [
    "## kmri_fnih_qcart_Chondrometrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b41a54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kmri_fnih_qcart_Chondrometrics'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a7f8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be7340",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407926f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcdbf6c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a1d84",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['WMTVCL', 'WMTSBA', 'WMTVCN', 'WMTMTH', 'WMTACS', 'WMTPD', 'WMTCAAB', 'WMTMTC', 'WMTMAV', 'WMTCTS', 'WMTACV', 'CMTMAT', 'CMTMTH', 'EMTMTH', 'IMTMTH', 'AMTMTH', 'PMTMTH', 'CMTPD', 'EMTPD', 'IMTPD', 'AMTPD', 'PMTPD', 'BMFVCL', 'BMFSBA', 'BMFVCN', 'BMFMTH', 'BMFACS', 'BMFPD', 'BMFCAAB', 'BMFMTC', 'BMFMAV', 'BMFCTS', 'BMFACV', 'CBMFMAT', 'CBMFMTH', 'EBMFMTH', 'IBMFMTH', 'CBMFPD', 'EBMFPD', 'IBMFPD', 'WMTFVCL', 'WMTFVCN', 'WMTFMTH', 'WMTFMAV', 'BMTFMAT', 'BMTFMTH', 'WLTVCL', 'WLTSBA', 'WLTVCN', 'WLTMTH', 'WLTACS', 'WLTPD', 'WLTCAAB', 'WLTMTC', 'WLTMAV', 'WLTCTS', 'WLTACV', 'CLTMAT', 'CLTMTH', 'ELTMTH', 'ILTMTH', 'ALTMTH', 'PLTMTH', 'CLTPD', 'ELTPD', 'ILTPD', 'ALTPD', 'PLTPD', 'BLFVCL', 'BLFSBA', 'BLFVCN', 'BLFMTH', 'BLFACS', 'BLFPD', 'BLFCAAB', 'BLFMTC', 'BLFMAV', 'BLFCTS', 'BLFACV', 'CBLFMAT', 'CBLFMT', 'EBLFMT', 'IBLFMT', 'CBLFPD', 'EBLFPD', 'IBLFPD', 'WLTFVCL', 'WLTFVCN', 'WLTFMTH', 'WLTFMAV', 'BLTFMAT', 'BLTFMTH'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BARCDFE'],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624a848",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022c0f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ebfa4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a960fa",
   "metadata": {},
   "source": [
    "## kmri_fnih_qcart_biomediq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa24ab99",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kmri_fnih_qcart_biomediq'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4102873",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a1be8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c46b14",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc02c7f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b61dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['MEDIALTIBIALCARTILAGE', 'LATERALTIBIALCARTILAGE', 'MEDIALFEMORALCARTILAGE', 'LATERALFEMORALCARTILAGE', 'PATELLARCARTILAGE', 'MEDIALMENISCUS', 'LATERALMENISCUS'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BARCDED'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ca7ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee23782",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb94e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc00e0",
   "metadata": {},
   "source": [
    "##  kmri_fnih_sbp_qmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef054b44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kmri_fnih_sbp_qmetrics'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9b2b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d53499",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4e75d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1cb9fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0230c160",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['SUBBAREA_MEDFEM', 'CURAVERAGE_SUBB_MEDFEM', 'CURSD_SUBB_MEDFEM', 'CUR_5PC_SUBB_MEDFEM', 'CUR_95PC_SUBB_MEDFEM', 'SCRAVERAGE_SUBB_MEDFEM', 'SCRSD_SUBB_MEDFEM', 'SCR_5PC_SUBB_MEDFEM', 'SCR_95PC_SUBB_MEDFEM', 'SUBBAREA_LATFEM', 'CURAVERAGE_SUBB_LATFEM', 'CURSD_SUBB_LATFEM', 'CUR_5PC_SUBB_LATFEM', 'CUR_95PC_SUBB_LATFEM', 'SCRAVERAGE_SUBB_LATFEM', 'SCRSD_SUBB_LATFEM', 'SCR_5PC_SUBB_LATFEM', 'SCR_95PC_SUBB_LATFEM', 'SUBBAREA_MEDTIB', 'CURAVERAGE_SUBB_MEDTIB', 'CURSD_SUBB_MEDTIB', 'CUR_5PC_SUBB_MEDTIB', 'CUR_95PC_SUBB_MEDTIB', 'SCRAVERAGE_SUBB_MEDTIB', 'SCRSD_SUBB_MEDTIB', 'SCR_5PC_SUBB_MEDTIB', 'SCR_95PC_SUBB_MEDTIB', 'SUBBAREA_LATTIB', 'CURAVERAGE_SUBB_LATTIB', 'CURSD_SUBB_LATTIB', 'CUR_5PC_SUBB_LATTIB', 'CUR_95PC_SUBB_LATTIB', 'SCRAVERAGE_SUBB_LATTIB', 'SCRSD_SUBB_LATTIB', 'SCR_5PC_SUBB_LATTIB', 'SCR_95PC_SUBB_LATTIB'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f48979",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb17e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e83a37",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a4cdbf",
   "metadata": {},
   "source": [
    "## kmri_fnih_sq_moaks_bicl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f872c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kmri_fnih_sq_moaks_bicl'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55378b3d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3303d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967bcd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da9f3a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138a081",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['MBMNFMA', 'MBMNFLA', 'MBMNFMC', 'MBMNFLC', 'MBMNFMP', 'MBMNFLP', 'MBMNSS', 'MBMNTMA', 'MBMNTLA', 'MBMNTMC', 'MBMNTLC', 'MBMNTMP', 'MBMNTLP', 'MBMNPM', 'MBMNPL'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['READER', 'MCMNTS', 'MTCMNTS'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c5ff3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36fe80",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df52c8f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2917583",
   "metadata": {},
   "source": [
    "## kmri_poma_incoa_moaks_bicl\n",
    "TODO: Not handled yet as column naming format doesn't use visit prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247d295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'kmri_poma_incoa_moaks_bicl'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21a15f2",
   "metadata": {},
   "source": [
    "## kmri_poma_tkr_chondrometrics\n",
    "TODO: Not handled yet as column naming format doesn't use visit prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a323da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'kmri_poma_tkr_chondrometrics'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3822b843",
   "metadata": {},
   "source": [
    "## kmri_poma_tkr_moaks_bicl\n",
    "TODO: Not handled yet as column naming format doesn't use visit prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13abbe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'kmri_poma_tkr_moaks_bicl'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd26048",
   "metadata": {},
   "source": [
    "## kmri_qcart_eckstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f05895",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kmri_qcart_eckstein'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390031a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a5c97",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7221f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e38e6a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5cb97b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['CBLFMAT', 'CBMFPD', 'BMFACV', 'BMTFMTH', 'WLTFMAV', 'IMTMTH', 'PLTMTH', 'BLFVCL', 'WMTCTS', 'BMFPD', 'BMFMTC', 'EMTMTH', 'WLTVCL', 'BLFACS', 'WMTVCN', 'WMTMAV', 'EBLFPD', 'AMTPD', 'WLTFMTH', 'WMTMTH', 'EMTPD', 'WLTFVCL', 'CMTMTH', 'CLTMAT', 'ILTMTH', 'WMTCAAB', 'BMFVCL', 'PMTPD', 'BLFACV', 'BMTFMAT', 'WMTFMTH', 'IBLFPD', 'EBMFPD', 'BMFACS', 'CMTPD', 'BLTFMAT', 'WLTCTS', 'WLTMAV', 'IBMFMTH', 'WMTFMAV', 'AMTMTH', 'WMTFVCN', 'ALTPD', 'WMTSBA', 'BMFVCN', 'BLFMTC', 'ELTMTH', 'PLTPD', 'BLFMAV', 'IMTPD', 'WLTFVCN', 'BLFVCN', 'EBMFMTH', 'WLTACV', 'IBLFMT', 'ELTPD', 'BLFCAAB', 'WMTFVCL', 'WLTMTH', 'CMTMAT', 'WLTCAAB', 'BLFSBA', 'IBMFPD', 'BLFCTS', 'CLTMTH', 'WLTMTC', 'CLTPD', 'CBMFMTH', 'WMTPD', 'PMTMTH', 'BLFMTH', 'WMTACS', 'ILTPD', 'CBMFMAT', 'EBLFMT', 'WLTSBA', 'WMTACV', 'ALTMTH', 'CBLFPD', 'BLTFMTH', 'BMFCAAB', 'CBLFMT', 'WLTACS', 'BMFMTH', 'BMFCTS', 'BMFSBA', 'BMFMAV', 'BLFPD', 'WMTMTC', 'WLTVCN', 'WMTVCL', 'WLTPD'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BARCDFE'],\n",
    "\n",
    "}\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc69151",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48577233",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647aa3a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fad484",
   "metadata": {},
   "source": [
    "## kmri_qcart_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b264f70",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kmri_qcart_link'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea404e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08527f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e3c2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ad7ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71005245",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['LFT2AV', 'LTT2AV', 'MFT2AV', 'MTT2AV', 'PATT2AV'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba2661",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ee473",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75069d1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f2b7fe",
   "metadata": {},
   "source": [
    "## kmri_qcart_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b40f0dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kmri_qcart_vs'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c83fc4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812e70cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9304f57",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0edcc7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e294a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['PMFSADA'],\n",
    "\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['LTWVOL', 'PATTMAX', 'CLFTAVG', 'TRFNVOL', 'WFTAVG', 'CMFSABC', 'CMTSABC', 'PATBMEV', 'CLFTVAR', 'CLTSAAS', 'LTNVOL', 'LTSABC', 'TRFTMAX', 'PLFSAAS', 'LTRBMEV', 'LTTMAX', 'CMTTAVG', 'CLTSABC', 'PLFSADA', 'MTSABC', 'LPBMEV', 'MTNVOL', 'CLTSADA', 'CMTCAVG', 'MTSADA', 'CMFSAAS', 'PMFBMEV', 'CMTRENG', 'MTWVOL', 'PLFSABC', 'CLFWVOL', 'WFTVAR', 'CMFTVAR', 'CMTSADA', 'CMTSAAS', 'CLTRENG', 'CLFCAVG', 'CMFSADA', 'CLFRENG', 'CLTCAVG', 'CMTNVOL', 'WFTMAX', 'CMFTAVG', 'LTSAAS', 'CMTWVOL', 'CLFTMAX', 'MPBMEV', 'CMFCAVG', 'LTRENG', 'CLFSADA', 'CMFRENG', 'CLFSAAS', 'CMFWVOL', 'PLFTAVG', 'CLFSABC', 'MTRBMEV', 'CMTTVAR', 'LTTAVG', 'CLTTAVG', 'MTBMEV', 'PATCAVG', 'PLFRENG', 'CLFNVOL', 'CMTTMAX', 'MTTAVG', 'PMFTVAR', 'PLFWVOL', 'CLTNVOL', 'CLTWVOL', 'LTCAVG', 'PMFTAVG', 'PLFCAVG', 'LTBMEV', 'PMFCAVG', 'PLFTVAR', 'WFSADA', 'PATTAVG', 'MTCAVG', 'CLTTVAR', 'CMFNVOL', 'CLFBMEV', 'WFWVOL', 'CMFTMAX', 'TRFTAVG', 'WFSABC', 'MTRENG', 'MTSAAS', 'PATRENG', 'PMFWVOL', 'PLFNVOL', 'LTSADA', 'PMFSABC', 'MTTMAX', 'WFCAVG', 'TRFRENG', 'PATSAAS', 'CLTTMAX', 'MTTVAR', 'TRFWVOL', 'PMFRENG', 'PATNVOL', 'PLFTMAX', 'TRFCAVG', 'TRFSAAS', 'WFSAAS', 'PATWVOL', 'WFRENG', 'TRFTVAR', 'PLFBMEV', 'WFNVOL', 'PATSABC', 'PATTVAR', 'TRFSABC', 'TRFSADA', 'PMFSAAS', 'PMFNVOL', 'PMFTMAX', 'LTTVAR', 'CMFBMEV', 'PATSADA'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BARCDVS'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b87b68c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2273b24e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2514d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612cd9b7",
   "metadata": {},
   "source": [
    "## kmri_sq_bicl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df82d53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kmri_sq_bicl'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66cb0d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610c540",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7cbe1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99158303",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f67d7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['BNBMLS', 'BNBMLSK'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['READER'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fac832",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b8fcf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f28b2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a59a02",
   "metadata": {},
   "source": [
    "## kmri_sq_blksbml_bicl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71749867",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kmri_sq_blksbml_bicl'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f47aa8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4aa32",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175b219",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851f75b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755aef96",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['BBMLNUM'],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043c2b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e519c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8195c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c979f4e",
   "metadata": {},
   "source": [
    "## kmri_sq_moaks_bicl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba32271",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kmri_sq_moaks_bicl'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967bb15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf0ead7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff08d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c548f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935104d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {}\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250ed669",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aad42e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d817e464",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe44531",
   "metadata": {},
   "source": [
    "## kmri_sq_worms_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236abb12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kmri_sq_worms_link'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1affc5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b88526",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667400e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d386945b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab3494a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['MWPOPCY'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348b8ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568c1d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f213b93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be44383",
   "metadata": {},
   "source": [
    "## kxr_fnih_bti_duke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfeddce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kxr_fnih_bti_duke'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf1279",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf57c5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f1bd3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1873badc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e74140a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['BTI_H0', 'BTI_H1', 'BTI_H2', 'BTI_V0', 'BTI_V1', 'BTI_V2'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BARCDBTI'],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a7821",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae58b1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830cc14",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e073ef68",
   "metadata": {},
   "source": [
    "## kxr_fta_duryea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e8f83",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kxr_fta_duryea'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672eeec0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a9155",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621c7ac3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ee077",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dfdd62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['FTANGLE'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BRCDJD'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f638c09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351cfadd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7949b9c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b30c96",
   "metadata": {},
   "source": [
    "## kxr_qjsw_duryea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b589c1d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kxr_qjsw_duryea'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4200b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf75f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a092652",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9027e522",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4bb0d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['CFWDTH', 'MCMJSW', 'JSW175', 'JSW200', 'JSW250', 'JSW300', 'JSW225', 'TPCFDS', 'BMANG', 'JSW150', 'JSW275', 'LJSW850', 'LJSW900', 'LJSW700', 'LJSW825', 'LJSW750', 'LJSW875', 'LJSW725', 'LJSW775', 'LJSW800', 'XMJSW', 'IMPIXSZ'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BARCDJD'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283aefd8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1f05f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d712c02d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a94dc3",
   "metadata": {},
   "source": [
    "## kxr_qjsw_rel_duryea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bbddad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kxr_qjsw_rel_duryea'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db7c8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfca667",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b174009",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49992516",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006c8ec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['CFWDTH', 'MCMJSW', 'JSW175', 'JSW200', 'JSW250', 'JSW300', 'JSW225', 'TPCFDS', 'BMANG', 'JSW150', 'JSW275', 'LJSW850', 'LJSW900', 'LJSW700', 'LJSW825', 'LJSW750', 'LJSW875', 'LJSW725', 'LJSW775', 'LJSW800', 'XMJSW', 'IMPIXSZ'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BARCDJD'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f872d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b1dfb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f21dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb3bff",
   "metadata": {},
   "source": [
    "## kxr_sq_bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b24535",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kxr_sq_bu'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5559e7bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24267b01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58afd9e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836da00",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71993e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['XRJSM', 'XRJSL'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BARCDBU'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ff328",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af504a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa95a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c59db",
   "metadata": {},
   "source": [
    "## kxr_sq_rel_bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f759f1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'kxr_sq_rel_bu'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8562b0cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc54df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b32ab9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ace83e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ecc0d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['XRJSM', 'XRJSL'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['BARCDBU'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd16e71",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1f755",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247f3e7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e98b35",
   "metadata": {},
   "source": [
    "## measinventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef773d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'measinventory'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e8779",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce029ec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc2abe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4d7277",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd7a8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['AGE'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e177eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b6a8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f13061",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768b25dd",
   "metadata": {},
   "source": [
    "## MIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f2ee5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'mif'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03402a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db597ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80417e0",
   "metadata": {},
   "source": [
    "It isn't clear what to do with INGCODE, they seem to be 9 digits plus '.0' except for some values labelled 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0468e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c569a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d96906",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['INGCODE'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['MIFNAME', 'INGNAME'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538c139f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2380d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62205ee3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe3a1e",
   "metadata": {},
   "source": [
    "## MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19ac21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'mri'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb445b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757270c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81abe2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376dc107",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15598691",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only dates, missing, and NA values\n",
    "'date': ['MRDATE'],\n",
    "\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['MRSURDY'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['MEXAMTP', 'MRBARCD', 'MRTECID', 'MQCCMNT'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd2bd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c4186",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8f35c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b81e64d",
   "metadata": {},
   "source": [
    "## outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5b25ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'outcomes'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d4256",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65239f78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056b6d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ed778",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07e909",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only dates, missing, and NA values\n",
    "'date': ['ERKDATE', 'ELKDATE', 'ERHDATE', 'ELHDATE', 'EDDDATE'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949205aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc718a0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267bff6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e8dc8",
   "metadata": {},
   "source": [
    "## sageancillarystudy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d900f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'sageancillarystudy'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e74e1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa3961",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0ef8b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c11e4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f14cf4a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only dates, missing, and NA values\n",
    "'date': ['SAGEDATE'],\n",
    "\n",
    "# Columns with only unsigned ints, missing, and NA values\n",
    "'unsigned': ['SAGEAGE', 'SAGEGENDER', 'SAGEDM', 'SAGEDMMEDS', 'SAGEDMMOUTH', 'SAGEDMINJ', 'SAGEARM', 'SAGENOARM', 'SAGEEQFAIL', 'SAGECLOTH'],\n",
    "\n",
    "# Columns with only floats, missing, and NA values\n",
    "'float': ['SAGE'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a9562",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9111d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab5e45",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8290320f",
   "metadata": {},
   "source": [
    "## subjectchar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d51db5",
   "metadata": {},
   "source": [
    "The data that was held in SubjectChar files has been added to allclinical. Why subjectchar00 is still shipped is a mystery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6573cede",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Grab the variable names from both subjectchar000 and allclinical00\n",
    "tmp_df, _ = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + 'subjectchar00.sas7bdat',\n",
    "                                                            num_processes=6, user_missing=True)\n",
    "sc_vars = set(tmp_df.columns)\n",
    "tmp_df, _ = pyreadstat.read_file_multiprocessing(pyreadstat.read_sas7bdat, data_dir + 'allclinical00.sas7bdat',\n",
    "                                                            num_processes=6, user_missing=True)\n",
    "ac_vars = set(tmp_df.columns)\n",
    "\n",
    "# Display unique variables that are in subjectchar00 that aren't included in allclinical00\n",
    "print(sc_vars - ac_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ae964",
   "metadata": {},
   "source": [
    "Nothing. Seems like SubjectChar00 is included for no reason."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb6099",
   "metadata": {},
   "source": [
    "## xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b52b18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix = 'xray'\n",
    "column_uniformity_check(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e74e1f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = create_df(prefix)\n",
    "print(tmp_df.shape)\n",
    "print('\\nStarting dataframe size: {:.2f}MB'.format(tmp_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa3962",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_df, done_df = gather_column_data_stats(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0ef8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_stats_summary(tmp_df, data_stats_df)\n",
    "data_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c10e4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "suggest_conversions(data_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04cf4a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "targets = {\n",
    "# Columns with only dates, missing, and NA values\n",
    "'date': ['XRDATE'],\n",
    "\n",
    "# Columns with only strings, missing, and NA values\n",
    "'cat': ['EXAMTP', 'XRBARCD', 'XRTECID'],\n",
    "\n",
    "}\n",
    "\n",
    "new_df, missing_df = convert_columns(targets, data_stats_df, tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a9562",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sanity_check(new_df)\n",
    "print()\n",
    "print(new_df.dtypes)\n",
    "if not missing_df.empty:\n",
    "    print('\\nMissing values present, shadow dataframe created.')\n",
    "    print(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9101d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nFinal dataframe size: {:.2f}MB'.format(new_df.memory_usage(deep=True).sum() / (1024**2)))\n",
    "print('Shadow dataframe size: {:.2f}MB'.format(missing_df.memory_usage(deep=True).sum() / (1024**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab5e44",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(new_df, open('pkl/' + prefix + '_values.pkl', 'wb'))\n",
    "if not missing_df.empty:\n",
    "    pickle.dump(missing_df, open('pkl/' + prefix + '_missing_values.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
